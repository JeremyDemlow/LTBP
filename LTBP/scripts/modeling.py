# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/01c_Modeling_Script.ipynb.

# %% auto 0
__all__ = ['model_train']

# %% ../../nbs/01c_Modeling_Script.ipynb 3
from fastcore.script import Param, call_parse

from sklearn import preprocessing as processors
from sklearn.model_selection import train_test_split

from ..data.utils import snowflake_query, get_yaml_dicts, generate_data_lake_query
from LTBP.modeling.utils import (
    create_stage_and_query_stage_sf, create_sklearn_preprocess_baseline_dict, 
    return_list_of_vars, prepare_training_set
)
from ..modeling.custom_utils import evaluate
from .. import files

from machine_learning_utilities import preprocessing

from data_system_utilities.file_parsers import yaml
from data_system_utilities.snowflake.utils import make_stage_query_generator

from sklearn import metrics
from sklearn import preprocessing as processors
from sklearn.model_selection import train_test_split

import LTBP.modeling.models as ds_models
import pandas as pd
import sys
import pandas as pd
import sys
import os
import logging

# %% ../../nbs/01c_Modeling_Script.ipynb 7
@call_parse
def model_train(yaml_file_list: Param(help="YAML files to read", type=list, # noqa:
                                      default=['dataset.yaml', 'etl.yaml', 'experiment.yaml']),  # noqa:
                hyper_sub_size: Param(help="", type=int, default=2750000),  # noqa:
                train_size: Param(help="", type=int, default=5500000),  # noqa:
                evals: Param(help="logit threshold cut", type=int, default=10),  # noqa:
                train_model: Param(help="to subsample or not", type=str, default='True'),  # noqa:
                fit_only: Param(help="no tuning model training", type=str, default='False')):  # noqa:
    
    features, udf_inputs, etl, models = get_yaml_dicts(['features.yaml', 'udf_inputs.yaml', 'etl.yaml', 'models.yaml'])
    df = create_stage_and_query_stage_sf(
        sf=sf,
        etl=etl,
        udf_inputs=udf_inputs,
        train_or_inference=train_or_inference,
        experiment_name=experiment_name,
        experiment=experiment,
        indentification=models['idenfication']
        )

    cat_vars =[{f.upper() : values['transformation'][experiment_name]} for f, values in features.items() 
                if values['var_type'][experiment_name] == 'cat'
                and values['input_definition'] != 'LABEL']
    cont_vars =[{f.upper(): values['transformation'][experiment_name]} for f, values in features.items() 
                if values['var_type'][experiment_name] == 'cont'
                and values['input_definition'] != 'LABEL']

    feature_dict = create_sklearn_preprocess_baseline_dict(cat_vars=cat_vars, 
                                                           cont_vars=cont_vars)
    logging.info(feature_dict)
    cat_vars = return_list_of_vars(cat_vars)
    cont_vars = return_list_of_vars(cont_vars)
    logging.info(f"categorical variables: \n {cat_vars}")
    logging.info(f"continous variables: \n {cont_vars}")

    pipe = preprocessing.generate_sklearn_preprocessing_pipeline(
        feature_dict, impute=True, impute_strategy='mean'
    )

    adls_path = os.path.join((os.path.join(etl['data_lake_path'], 'experiments', experiment_name)
        if experiment 
        else os.path.join(etl_dict['data_lake_path'], 
        os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS')))
        , models['preprocessors_adls_path'])

    y_var=[k.upper() for k, v in features.items() if v['input_definition'] == 'LABEL']

    result = prepare_training_set(df,
                                  y_var=[k.upper() for k, v in features.items() if v['input_definition'] == 'LABEL'],
                                  y_scaler_type=models[experiment_name]['y_scaler_type'],
                                  adls_path=adls_path,
                                  sklearn_pipe=pipe,
                                  test_set=True,
                                  etl_dict=etl,
                                  models_dict=models,
                                  connection_str=os.environ[models["connection_str"]],
                                  experiment_name=experiment_name,
                                  as_type=int,
                                  identifiers=['ECID', 'SEASONYEAR']
                                  )
    if test_set:
        X_train, X_valid, X_test, y_train, y_valid, y_test, sklearn_pipe, scaler, id_list = result
    else:
        X_train, X_valid, y_train, y_valid, sklearn_pipe, scaler, id_list = result

    model_trainer = getattr(ds_models, models[experiment_name]['model_trainer'])

    cat_vars =[{f.upper() : values['transformation'][experiment_name]} for f, values in features.items() 
                if values['var_type'][experiment_name] == 'cat'
                and values['input_definition'] != 'LABEL']
    cont_vars =[{f.upper(): values['transformation'][experiment_name]} for f, values in features.items() 
                if values['var_type'][experiment_name] == 'cont'
                and values['input_definition'] != 'LABEL']

    feature_dict = create_sklearn_preprocess_baseline_dict(cat_vars=cat_vars, 
                                                           cont_vars=cont_vars)
    logging.info(feature_dict)
    cat_vars = return_list_of_vars(cat_vars)
    cont_vars = return_list_of_vars(cont_vars)
    logging.info(f"categorical variables: \n {cat_vars}")
    logging.info(f"continous variables: \n {cont_vars}")

    pipe = preprocessing.generate_sklearn_preprocessing_pipeline(
        feature_dict, impute=True, impute_strategy='mean'
    )

    adls_path = os.path.join((os.path.join(etl['data_lake_path'], 'experiments', experiment_name)
        if experiment
        else os.path.join(etl_dict['data_lake_path'],
        os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS')))
        , models['preprocessors_adls_path'])

    model = model_trainer(X_train, X_valid, y_train, y_valid,
        evals=evals, sub=hyper_sub_size, train=train_size)

    y_var=[k.upper() for k, v in features.items() if v['input_definition'] == 'LABEL']

    """
    Custom needs for each project type this works for a binary classification
    this is not my best work, but trying to put something together 
    this is dry I am sure i could make this just a few lines 
    """
    result_dict = {}
    logging.info('Training Set Evaluation')

    eval_list_train = evaluate(model, X_train, y_train, y_var, feature_importance=True)
    metric1, metric2, metric3, columns, fi_permutation = eval_list_train
    result_dict['training_metrics']={k: v for k, v in zip(columns, [metric1]+[metric2]+[metric3])}
    result_dict['fi_train']={k:v for k, v in fi_permutation[:10].values}
    logging.info('Validation Set Evaluation')
    eval_list_valid = evaluate(model, X_valid, y_valid, y_var, feature_importance=True)
    metric1, metric2, metric3, columns, fi_permutation = eval_list_train
    result_dict['valid_metrics']={k: v for k, v in zip(columns, [metric1]+[metric2]+[metric3])}
    result_dict['fi_valid']={k:v for k, v in fi_permutation[:10].values}
    if X_test is not None:
        logging.info('Test Set Evaluation')
        eval_list_test = evaluate(model, X_test, y_test, y_var, feature_importance=True)
        metric1, metric2, metric3, columns, fi_permutation = eval_list_train
        result_dict['test_metrics']={k: v for k, v in zip(columns, [metric1]+[metric2]+[metric3])}
        result_dict['fi_test']={k:v for k, v in fi_permutation[:10].values}

    sf = snowflake_query(sfSchema='LTBP')
    send_holdout_results_to_sf(sf, id_list, y_pred_proba, experiment, experiment_name, etl, models)

    adls_path = os.path.join((os.path.join(etl['data_lake_path'], 'experiments', experiment_name)
        if experiment 
        else os.path.join(etl_dict['data_lake_path'], 
        os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS'))))

    project_log_df = project_log.project_log(
        snowflake_connection=sf,
        table_name=models['tracking_table'],
        action_description=models[experiment_name]["description"],
        transaction_type="model_training",
        artifacts=json.dumps({"azure_parent_folder": adls_path}),
        metrics=json.dumps(result_dict),
        append_or_replace="append",
    )
    logging.info(f'project log preview:\n{project_log_df.head(2)}')

# %% ../../nbs/01c_Modeling_Script.ipynb 11
from data_system_utilities.azure.storage import FileHandling
from data_system_utilities.file_parsers import yaml
from data_system_utilities.snowflake.utils import make_stage_query_generator

from machine_learning_utilities import preprocessing

from ..data.utils import snowflake_query, get_yaml_dicts, generate_data_lake_query

from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

from rfpimp import *

import sklearn.preprocessing as y_transform
import os
import logging
import pickle
