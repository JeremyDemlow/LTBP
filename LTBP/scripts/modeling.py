# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/01c_Modeling_Script.ipynb.

# %% auto 0
__all__ = ['model_train']

# %% ../../nbs/01c_Modeling_Script.ipynb 3
from fastcore.script import Param, call_parse

from ..data.utils import snowflake_query, get_yaml_dicts
from LTBP.modeling.utils import (
    create_stage_and_query_stage_sf, create_sklearn_preprocess_baseline_dict,
    return_list_of_vars, prepare_training_set, save_sklearn_object_to_data_lake
)
from ..modeling.custom_utils import evaluate, send_holdout_results_to_sf

from machine_learning_utilities import preprocessing
from machine_learning_utilities.project_log import project_log

from sklearn.pipeline import Pipeline

import LTBP.modeling.models as ds_models
import datetime
import os
import logging
import json
import pytz

# %% ../../nbs/01c_Modeling_Script.ipynb 8
@call_parse
def model_train(
    yaml_file_list: Param(help="YAML files to read", type=list, default=['features.yaml', 'udf_inputs.yaml', 'etl.yaml', 'models.yaml']),  # noqa:
    experiment_name: Param(help="YAML section to read", type=str, default='BASELINE'),  # noqa:
    experiment: Param(help="YAML section to read", type=bool, default=True),  # noqa:
    test_set: Param(help="Create a Test Set From Training Data", type=bool, default=True),  # noqa:
    sfSchema: Param(help="dev queries dev schema anything else will query project schema", type=str, default='dev')  # noqa:
    ):  # noqa:

    # Grab all yaml files for current probject
    features, udf_inputs, etl_dict, models_dict = get_yaml_dicts(yaml_file_list)

    # Create Snowflake Stage and Query Experiment location or commit location and return training data
    sf = snowflake_query(sfSchema='dev' if sfSchema.lower() == 'dev' else sfSchema)
    df = create_stage_and_query_stage_sf(
        sf=sf,
        features=features,
        etl=etl_dict,
        udf_inputs=udf_inputs,
        train_or_inference='TRAINING',
        experiment_name=experiment_name,
        experiment=experiment,
        indentification=models_dict['identification']
    )

    # Choosing an adls path depending on experiment being true or false
    adls_path = os.path.join(
        (os.path.join(etl_dict['data_lake_path'], 'experiments', experiment_name)
         if experiment
         else os.path.join(
             etl_dict['data_lake_path'],
             os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS'))
         ), models_dict['preprocessors_adls_path'], models_dict[experiment_name]['model_trainer'])

    # Grab all Categorical and Continous Variables for Modeling
    cat_vars = [{f.upper(): values['transformation'][experiment_name]} for f, values in features.items()
                if values['var_type'][experiment_name] == 'cat'
                and values['input_definition'] != 'LABEL']
    cont_vars = [{f.upper(): values['transformation'][experiment_name]} for f, values in features.items()
                 if values['var_type'][experiment_name] == 'cont'
                 and values['input_definition'] != 'LABEL']
    y_var = [k.upper() for k, v in features.items() if v['input_definition'] == 'LABEL']

    # Create Dictionary and create sklearn preprocessing Pipeline
    feature_dict = create_sklearn_preprocess_baseline_dict(cat_vars=cat_vars,
                                                           cont_vars=cont_vars)
    logging.info(feature_dict)
    cat_vars = return_list_of_vars(cat_vars)
    cont_vars = return_list_of_vars(cont_vars)
    logging.info(f"categorical variables: \n {cat_vars}")
    logging.info(f"continous variables: \n {cont_vars}")
    pipe = preprocessing.generate_sklearn_preprocessing_pipeline(
        feature_dict, impute=True, impute_strategy='mean'
    )

    # Preprocess and split data set to return neccessary object for modeling
    result = prepare_training_set(df,
                                  y_var=[k.upper() for k, v in features.items() if v['input_definition'] == 'LABEL'],
                                  y_scaler_type=models_dict[experiment_name]['y_scaler_type'],
                                  adls_path=adls_path,
                                  sklearn_pipe=pipe,
                                  test_set=test_set,
                                  etl_dict=etl_dict,
                                  models_dict=models_dict,
                                  connection_str=os.environ[models_dict["connection_str"]],
                                  experiment_name=experiment_name,
                                  as_type=int,
                                  identifiers=['ECID', 'SEASONYEAR']
                                  )
    X_train, X_valid, X_test, y_train, y_valid, y_test, sklearn_pipe, scaler, id_list = result
    # Choosing model from models.py to use from models.yaml file
    model_trainer = getattr(ds_models, models_dict[experiment_name]['model_trainer'])
    model = model_trainer(X_train,
                          X_valid,
                          y_train,
                          y_valid,
                          evals=models_dict[experiment_name]['hyperopt_evals'],
                          sub=models_dict[experiment_name]['hyper_opt_subsample_size'],
                          train=models_dict[experiment_name]['training_subsample_size'])

    """
    Custom needs for each project type this works for a binary classification
    this is not my best work, but trying to put something together
    this is dry I am sure i could make this just a few lines
    """
    result_dict = {}
    logging.info('Training Set Evaluation')

    eval_list_train = evaluate(model, X_train, y_train, y_var, feature_importance=True, plot=False)
    metric1, metric2, metric3, columns, _, _, fi_permutation = eval_list_train
    result_dict['training_metrics'] = {k: v for k, v in zip(columns, [metric1]+[metric2]+[metric3])}
    result_dict['fi_train'] = {k: v for k, v in fi_permutation[:10].values}
    logging.info('Validation Set Evaluation')
    eval_list_valid = evaluate(model, X_valid, y_valid, y_var, feature_importance=True, plot=False)
    metric1, metric2, metric3, columns, y_pred_proba, y_pred, fi_permutation = eval_list_valid
    result_dict['valid_metrics'] = {k: v for k, v in zip(columns, [metric1]+[metric2]+[metric3])}
    result_dict['fi_valid'] = {k: v for k, v in fi_permutation[:10].values}
    if X_test is not None:
        logging.info('Test Set Evaluation')
        eval_list_test = evaluate(model, X_test, y_test, y_var, feature_importance=True, plot=False)
        metric1, metric2, metric3, columns, y_pred_proba, y_pred, fi_permutation = eval_list_test
        result_dict['test_metrics'] = {k: v for k, v in zip(columns, [metric1]+[metric2]+[metric3])}
        result_dict['fi_test'] = {k: v for k, v in fi_permutation[:10].values}

    sf = snowflake_query(sfSchema='LTBP')
    send_holdout_results_to_sf(sf=sf,
                               id_list=id_list,
                               probs=y_pred_proba,
                               experiment=experiment,
                               experiment_name=experiment_name,
                               etl_dict=etl_dict,
                               model_dict=models_dict)

    adls_path = os.path.join(
        (os.path.join(etl_dict['data_lake_path'], 'experiments', experiment_name)
         if experiment else os.path.join(
             etl_dict['data_lake_path'], os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS'))
         )
    )
    custom_project_log = [
        {
            'action_description': models_dict[experiment_name]["description"],
            'transaction_type': "model_training",
            'commitid': os.getenv("CI_COMMIT_SHA", 'LocalRunNBS'),
            'environment': os.getenv("prod_or_dev", None),
            'branch': os.getenv("CI_COMMIT_REF_SLUG", None),
            'timestamp': datetime.datetime.now(pytz.timezone("US/Mountain")).strftime('%Y-%m-%d %H:%M:%S'),
            'artifacts': json.dumps({"azure_parent_folder": adls_path}),
            'metrics': json.dumps(result_dict),
            'experiment_name': experiment_name,
            'experiment': experiment,
            'production_model': False,
            'ever_production': False,
        }
    ]

    project_log_df = project_log.project_log(
        snowflake_connection=sf,
        table_name=models_dict['tracking_table'],
        custom_schema=custom_project_log,
        append_or_replace="append",
    )
    logging.info(f'project log preview:\n{project_log_df}')
    logging.info(f'project log values preview:\n{project_log_df.loc[0].values}')

    # Saving sklearn pipeline to adls
    logging.info('Saving model and sending it to adls')
    full_pipeline = Pipeline([('preprocessing', pipe), ('classification', model)])
    adls_path = os.path.join(adls_path, models_dict['modeling_adls_path'], models_dict[experiment_name]['model_trainer'])
    save_sklearn_object_to_data_lake(
        save_object=full_pipeline,
        adls_path=adls_path,
        file_name=(models_dict[experiment_name]['model_trainer']
                   + os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS')
                   + experiment_name+'.pkl'
                   ),
        container_name=etl_dict['azure_container'],
        connection_str=os.environ[models_dict['connection_str']]
    )
