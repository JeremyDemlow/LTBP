<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Inference utilities used in this project">

<title>LTBP - Inference Script</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="LTBP - Inference Script">
<meta property="og:description" content="Inference utilities used in this project">
<meta property="og:site-name" content="LTBP">
<meta name="twitter:title" content="LTBP - Inference Script">
<meta name="twitter:description" content="Inference utilities used in this project">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">LTBP</span>
    </a>
  </div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Inference Script</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Project Overview</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Tutorials</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_preparation_example.html" class="sidebar-item-text sidebar-link">Data Creation Process</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modeling_example.html" class="sidebar-item-text sidebar-link">Iterate Upon a Model</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./calling_library_cli.html" class="sidebar-item-text sidebar-link">Use Your CLI Commands</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Library Scripts</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_creation_script.html" class="sidebar-item-text sidebar-link">Data Creation Script</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modeling_script.html" class="sidebar-item-text sidebar-link">Modeling Script</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference_script.html" class="sidebar-item-text sidebar-link active">Inference Script</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Library Functions</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_utils.html" class="sidebar-item-text sidebar-link">Data Utils</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./model_utilities.html" class="sidebar-item-text sidebar-link">Model Utils</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./models.html" class="sidebar-item-text sidebar-link">Models</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./model_utilities_custom.html" class="sidebar-item-text sidebar-link">Model Utils</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference_utilities.html" class="sidebar-item-text sidebar-link">Inference Utils</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#script" id="toc-script" class="nav-link active" data-scroll-target="#script">Script</a>
  <ul class="collapse">
  <li><a href="#model_inference" id="toc-model_inference" class="nav-link" data-scroll-target="#model_inference">model_inference</a></li>
  </ul></li>
  <li><a href="#local-development" id="toc-local-development" class="nav-link" data-scroll-target="#local-development">Local Development</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/JeremyDemlow/LTBP/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Inference Script</h1>
</div>

<div>
  <div class="description">
    Inference utilities used in this project
  </div>
</div>


<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="script" class="level1">
<h1>Script</h1>
<p>This is the DSDE standard process for using Xboost with hyperopt</p>
<hr>
<p><a href="https://github.com/JeremyDemlow/LTBP/blob/main/LTBP/scripts/inference.py#L23" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="model_inference" class="level3">
<h3 class="anchored" data-anchor-id="model_inference">model_inference</h3>
<blockquote class="blockquote">
<pre><code> model_inference (yaml_file_list:list&lt;YAMLfilestoread&gt;,
                  experiment_name:str&lt;tellfunctionwhatexperimentisbeingran
                  &gt;, experiment:&lt;addexperimentstateitisnotanexperiment&gt;, s
                  fSchema:str&lt;devqueriesdevschemaanythingelsewillqueryproj
                  ectschema&gt;)</code></pre>
</blockquote>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 38%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>yaml_file_list</td>
<td>list <yaml files="" to="" read=""></yaml></td>
<td>noqa:</td>
</tr>
<tr class="even">
<td>experiment_name</td>
<td>str <tell function="" what="" experiment="" is="" being="" ran=""></tell></td>
<td>noqa:</td>
</tr>
<tr class="odd">
<td>experiment</td>
<td><add experiment="" state="" it="" is="" not="" an=""></add></td>
<td>noqa:</td>
</tr>
<tr class="even">
<td>sfSchema</td>
<td>str <dev queries="" dev="" schema="" anything="" else="" will="" query="" project=""></dev></td>
<td>noqa:</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="local-development" class="level1">
<h1>Local Development</h1>
<p>What ended up happening here was that during the development process there is a desire to be able to have more than one production model that then can logic on top of that as a view to do things like an ensemble or have predictions for a cohort that the model doesn’t perform well in allowing for that cohort to have a different prediction. Regardless of the reason that functionality seems to be important for the future so having it written is good it is a little messy.</p>
<p>The logical question is why wouldn’t we want to do the same thing for training a model and the simplest answer to that is that model training is much longer than inference. Also for none production models this will still need a matrix call that allows concurrency or pushing to multi vms similar to shazam and resort visitation forecasting.</p>
<p>When we have two differing models that have things like for example a different data structure like a deep learning model and a sklearn model then this design will need to have more work done.</p>
<p>Again this process is to get us to a safe location to work quickly with small amounts of changes when working in the 80-90% of the current projects. In the future we will have a more class like structure allowing for more flexibility hang in there with us as we develop the next stage of the modeling process here at vail</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>experiment_name <span class="op">=</span> <span class="st">'BASELINE'</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>experiment <span class="op">=</span> <span class="va">False</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>yaml_file_list <span class="op">=</span> [<span class="st">'features.yaml'</span>, <span class="st">'udf_inputs.yaml'</span>, <span class="st">'etl.yaml'</span>, <span class="st">'models.yaml'</span>]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>sfSchema<span class="op">=</span><span class="st">'LTBP'</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>features, udf_inputs, etl_dict, models_dict <span class="op">=</span> get_yaml_dicts(yaml_file_list)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>adls_paths <span class="op">=</span> []</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>model_names <span class="op">=</span> []</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>experiment_names <span class="op">=</span> []</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>experiments <span class="op">=</span> []</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>commit_ids <span class="op">=</span> []</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> sfSchema.lower() <span class="op">!=</span> <span class="st">'dev'</span>:</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    sf <span class="op">=</span> snowflake_query(sfSchema<span class="op">=</span>sfSchema)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    prod_model <span class="op">=</span> sf.run_sql_str(<span class="ss">f'''SELECT * </span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="ss">    FROM MACHINELEARNINGOUTPUTS.</span><span class="sc">{</span>sfSchema<span class="sc">}</span><span class="ss">.</span><span class="sc">{</span>models_dict[<span class="st">'tracking_table'</span>]<span class="sc">}</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="ss">    WHERE PRODUCTION_MODEL</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="ss">    '''</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    sf.run_sql_str(<span class="ss">f"DROP TABLE IF EXISTS MACHINELEARNINGOUTPUTS.</span><span class="sc">{</span>sfSchema<span class="sc">}</span><span class="ss">.</span><span class="sc">{</span>models_dict[<span class="st">'inference_sf_table_name'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, v <span class="kw">in</span> prod_model.iterrows():</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>        adls_path <span class="op">=</span> os.path.join(</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        (os.path.join(etl_dict[<span class="st">'data_lake_path'</span>], <span class="st">'experiments'</span>, v[<span class="st">'EXPERIMENT_NAME'</span>])</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> v[<span class="st">'EXPERIMENT'</span>]</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>          <span class="cf">else</span> os.path.join(</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>              etl_dict[<span class="st">'data_lake_path'</span>], v[<span class="st">'COMMITID'</span>], v[<span class="st">'EXPERIMENT_NAME'</span>])))</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        adls_paths.append(adls_path)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>        model_name <span class="op">=</span> (models_dict[v[<span class="st">'EXPERIMENT_NAME'</span>]][<span class="st">'model_trainer'</span>]<span class="op">+</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>                      v[<span class="st">'COMMITID'</span>]<span class="op">+</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>                      v[<span class="st">'EXPERIMENT_NAME'</span>]<span class="op">+</span><span class="st">'.pkl'</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>                     )</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>        model_names.append(model_name)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>        experiment_names.append(v[<span class="st">'EXPERIMENT_NAME'</span>])</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>        experiments.append(v[<span class="st">'EXPERIMENT'</span>])</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>        commit_ids.append(v[<span class="st">'COMMITID'</span>])</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>    adls_path <span class="op">=</span> os.path.join(</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>            (os.path.join(etl_dict[<span class="st">'data_lake_path'</span>], <span class="st">'experiments'</span>, experiment_name)</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>             <span class="cf">if</span> experiment</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>             <span class="cf">else</span> os.path.join(</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>                etl_dict[<span class="st">'data_lake_path'</span>], os.environ.get(<span class="st">'CI_COMMIT_SHA'</span>, <span class="st">'LocalRunNBS'</span>))))</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>    adls_paths.append(adls_path)</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>    model_name <span class="op">=</span> (models_dict[experiment_name][<span class="st">'model_trainer'</span>]</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>                  <span class="op">+</span> os.environ.get(<span class="st">'CI_COMMIT_SHA'</span>, <span class="st">'LocalRunNBS'</span>)</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>                  <span class="op">+</span> experiment_name<span class="op">+</span><span class="st">'.pkl'</span></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>                  )</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>    model_names.append(model_name)</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>    experiment_names.append(experiment_name)</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>    experiments.append(experiment)</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> adl_path, model_name, exp_name, com_id <span class="kw">in</span> <span class="bu">zip</span>(adls_paths, model_names, experiment_names, commit_ids):</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>    df_infer <span class="op">=</span> create_stage_and_query_stage_sf(</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>        sf<span class="op">=</span>sf,</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>        features<span class="op">=</span>features,</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>        etl<span class="op">=</span>etl_dict,</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>        udf_inputs<span class="op">=</span>udf_inputs,</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>        train_or_inference<span class="op">=</span><span class="st">'INFERENCE'</span>,</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>        experiment_name<span class="op">=</span>exp_name,</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>        experiment<span class="op">=</span>experiment,</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>        indentification<span class="op">=</span>models_dict[<span class="st">'identification'</span>],</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>        extra_statement<span class="op">=</span><span class="st">'LIMIT 1000'</span>  <span class="co"># Can add limit when experimenting 'LIMIT 1000'</span></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> pull_sklearn_object_from_adls(</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>            adls_path<span class="op">=</span>os.path.join(adl_path,</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>                                   models_dict[<span class="st">'modeling_adls_path'</span>],</span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>                                   models_dict[exp_name][<span class="st">'model_trainer'</span>]</span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>                                  ) <span class="op">+</span> <span class="st">'/'</span>,</span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>            file_name<span class="op">=</span>model_name,</span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>            drop_local_path<span class="op">=</span><span class="st">'./models/'</span>,</span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>            container_name<span class="op">=</span>etl_dict[<span class="st">'azure_container'</span>],</span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>            connection_str<span class="op">=</span>os.environ[models_dict[<span class="st">'connection_str'</span>]]</span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>    sf_df <span class="op">=</span> df_infer[models_dict[<span class="st">'identification'</span>]].copy()</span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Change Here Name change for a regression and to predict or multi-labled needs some work</span></span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a>    sf_df[<span class="st">'PROBABILITY'</span>] <span class="op">=</span> model.predict_proba(df_infer)[:, <span class="dv">1</span>]</span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a>    date_created <span class="op">=</span> datetime.datetime.today().strftime(<span class="st">'%Y-%m-</span><span class="sc">%d</span><span class="st"> %H:%M:%S'</span>)</span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a>    sf_df[<span class="st">'CI_COMMIT_SHA'</span>] <span class="op">=</span> os.environ.get(<span class="st">'CI_COMMIT_SHA'</span>, <span class="st">'LocalRunNBS'</span>)</span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a>    sf_df[<span class="st">'DATE_CREATED'</span>] <span class="op">=</span> datetime.datetime.today().strftime(<span class="st">'%Y-%m-</span><span class="sc">%d</span><span class="st"> %H:%M:%S'</span>)</span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a>    sf_df[<span class="st">'EXPERIMENT'</span>] <span class="op">=</span> exp_name</span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>    file_name <span class="op">=</span> <span class="ss">f"predictions_</span><span class="sc">{</span>os<span class="sc">.</span>environ<span class="sc">.</span>get(<span class="st">'CI_COMMIT_SHA'</span>,<span class="st">'LocalRunNBS'</span>)<span class="op">+</span>exp_name<span class="sc">}</span><span class="ss">.csv"</span></span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Saving as a .csv for simple reading from adls download using dask would be best here</span></span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a>    sf_df.to_csv(file_name, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a>    logging.info(<span class="ss">f'preview predictions being added:</span><span class="ch">\n</span><span class="sc">{</span>sf_df<span class="sc">.</span>head(<span class="dv">3</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a>    logging.info(<span class="ss">f'preview predictions values addes:</span><span class="ch">\n</span><span class="sc">{</span>sf_df<span class="sc">.</span>iloc[<span class="dv">0</span>]<span class="sc">.</span>values<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a>    logging.info(<span class="ss">f'preview predictions being added columns:</span><span class="ch">\n</span><span class="sc">{</span>sf_df<span class="sc">.</span>columns<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a>    adl_path <span class="op">=</span> (adl_path <span class="cf">if</span> sfSchema.lower() <span class="op">==</span> <span class="st">'dev'</span> <span class="kw">and</span> experiment</span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a>     <span class="cf">else</span> os.path.join((os.path.join(</span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a>         etl_dict[<span class="st">'data_lake_path'</span>], <span class="st">'experiments'</span>, experiment_name)</span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">if</span> experiment</span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">else</span></span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a>                        os.path.join(etl_dict[<span class="st">'data_lake_path'</span>],com_id,exp_name))</span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a>                      )</span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a>               )</span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a>    az <span class="op">=</span> FileHandling(os.environ[models_dict[<span class="st">'connection_str'</span>]])</span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a>    az.upload_file(</span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a>        azure_file_path<span class="op">=</span>os.path.join(adl_path,</span>
<span id="cb2-96"><a href="#cb2-96" aria-hidden="true" tabindex="-1"></a>                                     models_dict[<span class="st">'predictions_adls_path'</span>],</span>
<span id="cb2-97"><a href="#cb2-97" aria-hidden="true" tabindex="-1"></a>                                     models_dict[exp_name][<span class="st">'model_trainer'</span>]),</span>
<span id="cb2-98"><a href="#cb2-98" aria-hidden="true" tabindex="-1"></a>        local_file_path<span class="op">=</span>file_name,</span>
<span id="cb2-99"><a href="#cb2-99" aria-hidden="true" tabindex="-1"></a>        container_name<span class="op">=</span>etl_dict[<span class="st">'azure_container'</span>],</span>
<span id="cb2-100"><a href="#cb2-100" aria-hidden="true" tabindex="-1"></a>        overwrite<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb2-101"><a href="#cb2-101" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-102"><a href="#cb2-102" aria-hidden="true" tabindex="-1"></a>    os.unlink(file_name)</span>
<span id="cb2-103"><a href="#cb2-103" aria-hidden="true" tabindex="-1"></a>    stage_url <span class="op">=</span> <span class="ss">f"azure://</span><span class="sc">{</span>etl_dict[<span class="st">'azure_account'</span>]<span class="sc">}</span><span class="ss">.blob.core.windows.net/</span><span class="sc">{</span>etl_dict[<span class="st">'azure_container'</span>]<span class="sc">}</span><span class="ss">/"</span></span>
<span id="cb2-104"><a href="#cb2-104" aria-hidden="true" tabindex="-1"></a>    preds_file_path <span class="op">=</span> os.path.join(adl_path,</span>
<span id="cb2-105"><a href="#cb2-105" aria-hidden="true" tabindex="-1"></a>                                   models_dict[<span class="st">'predictions_adls_path'</span>],</span>
<span id="cb2-106"><a href="#cb2-106" aria-hidden="true" tabindex="-1"></a>                                   models_dict[exp_name][<span class="st">'model_trainer'</span>],</span>
<span id="cb2-107"><a href="#cb2-107" aria-hidden="true" tabindex="-1"></a>                                   file_name)</span>
<span id="cb2-108"><a href="#cb2-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-109"><a href="#cb2-109" aria-hidden="true" tabindex="-1"></a>    sf <span class="op">=</span> snowflake_query(sfSchema<span class="op">=</span>sfSchema)</span>
<span id="cb2-110"><a href="#cb2-110" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> models_dict[<span class="st">'inference_sf_table_name'</span>].upper() <span class="kw">not</span> <span class="kw">in</span> sf.run_sql_str(<span class="st">"show tables;"</span>).name.tolist():</span>
<span id="cb2-111"><a href="#cb2-111" aria-hidden="true" tabindex="-1"></a>        sf.run_sql_str(create_table_query_from_df(sf_df, table_name_sf<span class="op">=</span>models_dict[<span class="st">'inference_sf_table_name'</span>], varchar<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb2-112"><a href="#cb2-112" aria-hidden="true" tabindex="-1"></a>    logging.info(<span class="st">"Pushing Forecasted Season from ADLS to Snowflake"</span>)</span>
<span id="cb2-113"><a href="#cb2-113" aria-hidden="true" tabindex="-1"></a>    adls_query <span class="op">=</span> adls_url_to_sf_query_generator(</span>
<span id="cb2-114"><a href="#cb2-114" aria-hidden="true" tabindex="-1"></a>        azure_path<span class="op">=</span>os.path.join(stage_url, preds_file_path),</span>
<span id="cb2-115"><a href="#cb2-115" aria-hidden="true" tabindex="-1"></a>        azure_sas_token<span class="op">=</span>os.environ[models_dict[<span class="st">'sas_token'</span>]],</span>
<span id="cb2-116"><a href="#cb2-116" aria-hidden="true" tabindex="-1"></a>        table_name<span class="op">=</span>models_dict[<span class="st">'inference_sf_table_name'</span>],</span>
<span id="cb2-117"><a href="#cb2-117" aria-hidden="true" tabindex="-1"></a>        database<span class="op">=</span>sf.connection_inputs[<span class="st">'database'</span>],</span>
<span id="cb2-118"><a href="#cb2-118" aria-hidden="true" tabindex="-1"></a>        schema<span class="op">=</span>sf.connection_inputs[<span class="st">'schema'</span>],</span>
<span id="cb2-119"><a href="#cb2-119" aria-hidden="true" tabindex="-1"></a>        skip_header<span class="op">=</span><span class="st">'1'</span>,</span>
<span id="cb2-120"><a href="#cb2-120" aria-hidden="true" tabindex="-1"></a>        file_type<span class="op">=</span><span class="st">'csv'</span>,</span>
<span id="cb2-121"><a href="#cb2-121" aria-hidden="true" tabindex="-1"></a>        pattern<span class="op">=</span><span class="st">'.*.csv'</span>)</span>
<span id="cb2-122"><a href="#cb2-122" aria-hidden="true" tabindex="-1"></a>    sf.run_sql_str(adls_query)</span>
<span id="cb2-123"><a href="#cb2-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-124"><a href="#cb2-124" aria-hidden="true" tabindex="-1"></a>    exp_table <span class="op">=</span> sf.run_sql_str(<span class="ss">f"""</span></span>
<span id="cb2-125"><a href="#cb2-125" aria-hidden="true" tabindex="-1"></a><span class="ss">    SELECT *</span></span>
<span id="cb2-126"><a href="#cb2-126" aria-hidden="true" tabindex="-1"></a><span class="ss">    FROM </span><span class="sc">{</span>models_dict[<span class="st">'inference_sf_table_name'</span>]<span class="sc">}</span></span>
<span id="cb2-127"><a href="#cb2-127" aria-hidden="true" tabindex="-1"></a><span class="ss">    WHERE DATE_CREATED = '</span><span class="sc">{</span>date_created<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb2-128"><a href="#cb2-128" aria-hidden="true" tabindex="-1"></a><span class="ss">    AND EXPERIMENT = '</span><span class="sc">{</span>exp_name<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb2-129"><a href="#cb2-129" aria-hidden="true" tabindex="-1"></a><span class="ss">    LIMIT 3</span></span>
<span id="cb2-130"><a href="#cb2-130" aria-hidden="true" tabindex="-1"></a><span class="ss">    """</span>)</span>
<span id="cb2-131"><a href="#cb2-131" aria-hidden="true" tabindex="-1"></a>    logging.info(<span class="ss">f'preview of queried table being added:</span><span class="ch">\n</span><span class="sc">{</span>exp_table<span class="sc">.</span>head(<span class="dv">3</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-132"><a href="#cb2-132" aria-hidden="true" tabindex="-1"></a>    logging.info(<span class="ss">f'preview predictions values addes:</span><span class="ch">\n</span><span class="sc">{</span>exp_table<span class="sc">.</span>iloc[<span class="dv">0</span>]<span class="sc">.</span>values<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:data_system_utilities.snowflake.utils:connection to snowflake established...
INFO:data_system_utilities.snowflake.query:executing query
INFO:data_system_utilities.snowflake.query:data loaded from snowflake
INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off
INFO:data_system_utilities.snowflake.utils:stage_query: 
 create or replace stage ltbpFY23LocalRunTest
url='azure://vaildtscadls.blob.core.windows.net/vailadls/projects/LTBP/FY23/LocalRunTest/BASELINE/'
credentials=(azure_sas_token='**MASKED**')
encryption=(type= 'NONE')
file_format = (type = parquet        )
INFO:data_system_utilities.snowflake.utils:connection to snowflake established...
INFO:data_system_utilities.snowflake.query:executing query
INFO:data_system_utilities.snowflake.query:data loaded from snowflake
INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off
INFO:data_system_utilities.snowflake.query:Stage area LTBPFY23LOCALRUNTEST successfully created.
INFO:root:adls snowflake stage query 
    select
    $1:"ECID"::varchar as ECID
, $1:"SEASONYEAR"::varchar as SEASONYEAR
, $1:"AGE"::varchar as AGE
, $1:"AVGVISITPERSEASON"::varchar as AVGVISITPERSEASON
, $1:"BOUGHTPASS"::varchar as BOUGHTPASS
, $1:"DESTINATIONGEOAFINITYLABEL"::varchar as DESTINATIONGEOAFINITYLABEL
, $1:"EVERCOREPASS"::varchar as EVERCOREPASS
, $1:"EVERPASS"::varchar as EVERPASS
, $1:"GENDERCODE"::varchar as GENDERCODE
, $1:"GUESTBEHAVIOR"::varchar as GUESTBEHAVIOR
, $1:"ISEPICMIXACTIVATED"::varchar as ISEPICMIXACTIVATED
, $1:"MARKETINGZONE"::varchar as MARKETINGZONE
, $1:"MOSTCOMMONTICKETCOMP"::varchar as MOSTCOMMONTICKETCOMP
, $1:"MOSTSUBSEASONVISITED"::varchar as MOSTSUBSEASONVISITED
, $1:"MOSTVISITEDREGION"::varchar as MOSTVISITEDREGION
, $1:"MOSTVISITEDRESORT"::varchar as MOSTVISITEDRESORT
, $1:"ONLYSINGLERESORTKEY"::varchar as ONLYSINGLERESORTKEY
, $1:"PARTNERRESORTSCANNERFLAG"::varchar as PARTNERRESORTSCANNERFLAG
, $1:"RESORTSVISITED"::varchar as RESORTSVISITED
, $1:"SKIERABILITYLABEL"::varchar as SKIERABILITYLABEL
, $1:"SUBSEASONSPERYEAR"::varchar as SUBSEASONSPERYEAR
, $1:"TOTALSEASONSSCANNED"::varchar as TOTALSEASONSSCANNED
, $1:"TOTALVISITS"::varchar as TOTALVISITS
, $1:"VISITMOSTINPEAK"::varchar as VISITMOSTINPEAK

    from @ltbpFY23LocalRunTest/inference_data/
    LIMIT 1000
    
INFO:data_system_utilities.snowflake.utils:connection to snowflake established...
INFO:data_system_utilities.snowflake.query:executing query
INFO:data_system_utilities.snowflake.query:data loaded from snowflake
INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off
INFO:root:Preview dataframe queried        ECID SEASONYEAR AGE AVGVISITPERSEASON BOUGHTPASS  \
0  57591278    2021/22   3                 0          0   
1  75561307    2021/22  21                 0          0   
2   4662642    2021/22  59                 0          0   
3  55384020    2021/22  28                 0          0   
4    230261    2021/22  32                 0          0   

  DESTINATIONGEOAFINITYLABEL EVERCOREPASS EVERPASS GENDERCODE GUESTBEHAVIOR  \
0                    Unknown            0        0          F   Lapsed Paid   
1                Destination            0        0          F   Lapsed Paid   
2                Destination            0        0          M   Lapsed Paid   
3                      Local            0        0          M   Lapsed Paid   
4                Destination            0        0          F   Lapsed Paid   

   ... MOSTVISITEDREGION MOSTVISITEDRESORT ONLYSINGLERESORTKEY  \
0  ...              None              None                None   
1  ...              None              None                None   
2  ...              None              None                None   
3  ...              None              None                None   
4  ...              None              None                None   

  PARTNERRESORTSCANNERFLAG RESORTSVISITED SKIERABILITYLABEL SUBSEASONSPERYEAR  \
0                        0              0              None              None   
1                        0              0              None              None   
2                        0              0              None              None   
3                        0              0              None              None   
4                        0              0              None              None   

  TOTALSEASONSSCANNED TOTALVISITS VISITMOSTINPEAK  
0                   0           0               0  
1                   0           0               0  
2                   0           0               0  
3                   0           0               0  
4                   0           0               0  

[5 rows x 24 columns]
INFO:root:Loading Sklearn Object to: ./models/train_xgbLocalRunTestBASELINE.pkl
INFO:data_system_utilities.azure.storage:Downloading projects/LTBP/FY23/experiments/BASELINE/modeling/train_xgb/train_xgbLocalRunTestBASELINE.pkl to ./models/train_xgbLocalRunTestBASELINE.pkl
INFO:data_system_utilities.azure.storage:Download complete
INFO:root:Sklearn Object Loaded
INFO:root:preview predictions being added:
       ECID SEASONYEAR  PROBABILITY CI_COMMIT_SHA         DATE_CREATED  \
0  57591278    2021/22     0.029840  LocalRunTest  2022-11-04 07:43:55   
1  75561307    2021/22     0.045436  LocalRunTest  2022-11-04 07:43:55   
2   4662642    2021/22     0.045249  LocalRunTest  2022-11-04 07:43:55   

  EXPERIMENT  
0   BASELINE  
1   BASELINE  
2   BASELINE  
INFO:root:preview predictions values addes:
['57591278' '2021/22' 0.029840026 'LocalRunTest' '2022-11-04 07:43:55'
 'BASELINE']
INFO:root:preview predictions being added columns:
Index(['ECID', 'SEASONYEAR', 'PROBABILITY', 'CI_COMMIT_SHA', 'DATE_CREATED',
       'EXPERIMENT'],
      dtype='object')
INFO:data_system_utilities.azure.storage:Uploading predictions_LocalRunTestBASELINE.csv, to Azure Storage projects/LTBP/FY23/LocalRunTest/BASELINE/predictions/train_xgb/predictions_LocalRunTestBASELINE.csv
INFO:data_system_utilities.azure.storage:Azure Upload Complete
INFO:data_system_utilities.snowflake.utils:connection to snowflake established...
INFO:data_system_utilities.snowflake.query:executing query
INFO:data_system_utilities.snowflake.query:data loaded from snowflake
INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off
INFO:root:Pushing Forecasted Season from ADLS to Snowflake
INFO:data_system_utilities.snowflake.copyinto:
copy into MACHINELEARNINGOUTPUTS.LTBP.LTBP_PREDICTIONS_FY23
from 'azure://vaildtscadls.blob.core.windows.net/vailadls/projects/LTBP/FY23/LocalRunTest/BASELINE/predictions/train_xgb/predictions_LocalRunTestBASELINE.csv'
file_format = (type = csv     skip_header = 1)
credentials= (azure_sas_token = '?sv=2019-12-12&amp;ss=bfqt&amp;srt=sco&amp;sp=rwdlacupx&amp;se=2031-01-22T06:17:14Z&amp;st=2021-01-21T22:17:14Z&amp;spr=https&amp;sig=kIHogByJjyVWyL6XupA0CBUB1iw12%2FeXWFQiOj5fB5c%3D')
pattern = '.*.csv';
INFO:data_system_utilities.snowflake.utils:connection to snowflake established...
INFO:data_system_utilities.snowflake.query:executing query
INFO:data_system_utilities.snowflake.query:data loaded from snowflake
INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off
INFO:data_system_utilities.snowflake.utils:connection to snowflake established...
INFO:data_system_utilities.snowflake.query:executing query
INFO:data_system_utilities.snowflake.query:data loaded from snowflake
INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off
INFO:root:preview of queried table being added:
       ECID SEASONYEAR  PROBABILITY CI_COMMIT_SHA         DATE_CREATED  \
0  57591278    2021/22     0.029840  LocalRunTest  2022-11-04 07:43:55   
1  75561307    2021/22     0.045436  LocalRunTest  2022-11-04 07:43:55   
2   4662642    2021/22     0.045249  LocalRunTest  2022-11-04 07:43:55   

  EXPERIMENT  
0   BASELINE  
1   BASELINE  
2   BASELINE  
INFO:root:preview predictions values addes:
['57591278' '2021/22' 0.029840026 'LocalRunTest' '2022-11-04 07:43:55'
 'BASELINE']
INFO:data_system_utilities.snowflake.utils:stage_query: 
 create or replace stage ltbpFY23LocalRunTest
url='azure://vaildtscadls.blob.core.windows.net/vailadls/projects/LTBP/FY23/LocalRunTest/NOHYPEROPT/'
credentials=(azure_sas_token='**MASKED**')
encryption=(type= 'NONE')
file_format = (type = parquet        )</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:data_system_utilities.snowflake.utils:connection to snowflake established...
INFO:data_system_utilities.snowflake.query:executing query
INFO:data_system_utilities.snowflake.query:data loaded from snowflake
INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off
INFO:data_system_utilities.snowflake.query:Stage area LTBPFY23LOCALRUNTEST successfully created.
INFO:root:adls snowflake stage query 
    select
    $1:"ECID"::varchar as ECID
, $1:"SEASONYEAR"::varchar as SEASONYEAR
, $1:"AGE"::varchar as AGE
, $1:"AVGVISITPERSEASON"::varchar as AVGVISITPERSEASON
, $1:"BOUGHTPASS"::varchar as BOUGHTPASS
, $1:"DESTINATIONGEOAFINITYLABEL"::varchar as DESTINATIONGEOAFINITYLABEL
, $1:"EVERCOREPASS"::varchar as EVERCOREPASS
, $1:"EVERPASS"::varchar as EVERPASS
, $1:"GENDERCODE"::varchar as GENDERCODE
, $1:"GUESTBEHAVIOR"::varchar as GUESTBEHAVIOR
, $1:"ISEPICMIXACTIVATED"::varchar as ISEPICMIXACTIVATED
, $1:"MARKETINGZONE"::varchar as MARKETINGZONE
, $1:"MOSTCOMMONTICKETCOMP"::varchar as MOSTCOMMONTICKETCOMP
, $1:"MOSTSUBSEASONVISITED"::varchar as MOSTSUBSEASONVISITED
, $1:"MOSTVISITEDREGION"::varchar as MOSTVISITEDREGION
, $1:"MOSTVISITEDRESORT"::varchar as MOSTVISITEDRESORT
, $1:"ONLYSINGLERESORTKEY"::varchar as ONLYSINGLERESORTKEY
, $1:"PARTNERRESORTSCANNERFLAG"::varchar as PARTNERRESORTSCANNERFLAG
, $1:"RESORTSVISITED"::varchar as RESORTSVISITED
, $1:"SKIERABILITYLABEL"::varchar as SKIERABILITYLABEL
, $1:"SUBSEASONSPERYEAR"::varchar as SUBSEASONSPERYEAR
, $1:"TOTALSEASONSSCANNED"::varchar as TOTALSEASONSSCANNED
, $1:"TOTALVISITS"::varchar as TOTALVISITS
, $1:"VISITMOSTINPEAK"::varchar as VISITMOSTINPEAK

    from @ltbpFY23LocalRunTest/inference_data/
    LIMIT 1000
    
INFO:data_system_utilities.snowflake.utils:connection to snowflake established...
INFO:data_system_utilities.snowflake.query:executing query
INFO:data_system_utilities.snowflake.query:data loaded from snowflake
INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off
INFO:root:Preview dataframe queried        ECID SEASONYEAR AGE AVGVISITPERSEASON BOUGHTPASS  \
0  63649827    2021/22  21                 0          0   
1  74541784    2021/22  32                 0          0   
2  70305244    2021/22  40                 0          0   
3  34674698    2021/22  36                 0          0   
4  28216761    2021/22  35                 0          0   

  DESTINATIONGEOAFINITYLABEL EVERCOREPASS EVERPASS GENDERCODE GUESTBEHAVIOR  \
0                    Unknown            0        0          F   Lapsed Paid   
1                    Unknown            0        0          F   Lapsed Paid   
2                Destination            0        0          M   Lapsed Paid   
3                Destination            0        0          F   Lapsed Paid   
4              International            0        0          F   Lapsed Paid   

   ... MOSTVISITEDREGION MOSTVISITEDRESORT ONLYSINGLERESORTKEY  \
0  ...              None              None                None   
1  ...              None              None                None   
2  ...              None              None                None   
3  ...              None              None                None   
4  ...              None              None                None   

  PARTNERRESORTSCANNERFLAG RESORTSVISITED SKIERABILITYLABEL SUBSEASONSPERYEAR  \
0                        0              0              None              None   
1                        0              0              None              None   
2                        0              0              None              None   
3                        0              0              None              None   
4                        0              0              None              None   

  TOTALSEASONSSCANNED TOTALVISITS VISITMOSTINPEAK  
0                   0           0               0  
1                   0           0               0  
2                   0           0               0  
3                   0           0               0  
4                   0           0               0  

[5 rows x 24 columns]
INFO:root:Loading Sklearn Object to: ./models/train_xgb_basicLocalRunTestNOHYPEROPT.pkl
INFO:data_system_utilities.azure.storage:Downloading projects/LTBP/FY23/experiments/NOHYPEROPT/modeling/train_xgb_basic/train_xgb_basicLocalRunTestNOHYPEROPT.pkl to ./models/train_xgb_basicLocalRunTestNOHYPEROPT.pkl
INFO:data_system_utilities.azure.storage:Download complete
INFO:root:Sklearn Object Loaded
INFO:root:preview predictions being added:
       ECID SEASONYEAR  PROBABILITY CI_COMMIT_SHA         DATE_CREATED  \
0  63649827    2021/22     0.020158  LocalRunTest  2022-11-04 07:44:03   
1  74541784    2021/22     0.022840  LocalRunTest  2022-11-04 07:44:03   
2  70305244    2021/22     0.028208  LocalRunTest  2022-11-04 07:44:03   

   EXPERIMENT  
0  NOHYPEROPT  
1  NOHYPEROPT  
2  NOHYPEROPT  
INFO:root:preview predictions values addes:
['63649827' '2021/22' 0.020157771 'LocalRunTest' '2022-11-04 07:44:03'
 'NOHYPEROPT']
INFO:root:preview predictions being added columns:
Index(['ECID', 'SEASONYEAR', 'PROBABILITY', 'CI_COMMIT_SHA', 'DATE_CREATED',
       'EXPERIMENT'],
      dtype='object')
INFO:data_system_utilities.azure.storage:Uploading predictions_LocalRunTestNOHYPEROPT.csv, to Azure Storage projects/LTBP/FY23/LocalRunTest/NOHYPEROPT/predictions/train_xgb_basic/predictions_LocalRunTestNOHYPEROPT.csv
INFO:data_system_utilities.azure.storage:Azure Upload Complete
INFO:data_system_utilities.snowflake.utils:connection to snowflake established...
INFO:data_system_utilities.snowflake.query:executing query
INFO:data_system_utilities.snowflake.query:data loaded from snowflake
INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off
INFO:root:Pushing Forecasted Season from ADLS to Snowflake
INFO:data_system_utilities.snowflake.copyinto:
copy into MACHINELEARNINGOUTPUTS.LTBP.LTBP_PREDICTIONS_FY23
from 'azure://vaildtscadls.blob.core.windows.net/vailadls/projects/LTBP/FY23/LocalRunTest/NOHYPEROPT/predictions/train_xgb_basic/predictions_LocalRunTestNOHYPEROPT.csv'
file_format = (type = csv     skip_header = 1)
credentials= (azure_sas_token = '?sv=2019-12-12&amp;ss=bfqt&amp;srt=sco&amp;sp=rwdlacupx&amp;se=2031-01-22T06:17:14Z&amp;st=2021-01-21T22:17:14Z&amp;spr=https&amp;sig=kIHogByJjyVWyL6XupA0CBUB1iw12%2FeXWFQiOj5fB5c%3D')
pattern = '.*.csv';
INFO:data_system_utilities.snowflake.utils:connection to snowflake established...
INFO:data_system_utilities.snowflake.query:executing query
INFO:data_system_utilities.snowflake.query:data loaded from snowflake
INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off
INFO:data_system_utilities.snowflake.utils:connection to snowflake established...
INFO:data_system_utilities.snowflake.query:executing query
INFO:data_system_utilities.snowflake.query:data loaded from snowflake
INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off
INFO:root:preview of queried table being added:
       ECID SEASONYEAR  PROBABILITY CI_COMMIT_SHA         DATE_CREATED  \
0  63649827    2021/22     0.020158  LocalRunTest  2022-11-04 07:44:03   
1  74541784    2021/22     0.022840  LocalRunTest  2022-11-04 07:44:03   
2  70305244    2021/22     0.028208  LocalRunTest  2022-11-04 07:44:03   

   EXPERIMENT  
0  NOHYPEROPT  
1  NOHYPEROPT  
2  NOHYPEROPT  
INFO:root:preview predictions values addes:
['63649827' '2021/22' 0.020157771 'LocalRunTest' '2022-11-04 07:44:03'
 'NOHYPEROPT']</code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>