{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Script\n",
    "\n",
    "> Inference utilities used in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp scripts.inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.script import Param, call_parse\n",
    "\n",
    "from LTBP.modeling.utils import create_stage_and_query_stage_sf\n",
    "from LTBP.data.utils import snowflake_query, get_yaml_dicts\n",
    "from LTBP.inference.utils import pull_sklearn_object_from_adls, prediction_to_adls_and_sf\n",
    "\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the DSDE standard process for using Xboost with hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def model_inference(\n",
    "    yaml_file_list: Param(help=\"YAML files to read\", type=list,  # noqa:\n",
    "                      default=['features.yaml', 'udf_inputs.yaml', 'etl.yaml', 'models.yaml']),  # noqa:\n",
    "    experiment_name: Param(help=\"tell function what experiment is being ran\", type=str, default='BASELINE'),  # noqa:\n",
    "    experiment: Param(help=\"add experiment state it is not an experiment\", type=bool, default=True),  # noqa:\n",
    "    sfSchema: Param(help=\"dev queries dev schema anything else will query project schema\", type=str, default='dev')  # noqa:\n",
    "    ):  # noqa:\n",
    "\n",
    "    _, udf_inputs, etl_dict, models_dict = get_yaml_dicts(yaml_file_list)\n",
    "\n",
    "    adls_path = os.path.join(\n",
    "        (os.path.join(etl_dict['data_lake_path'], 'experiments', experiment_name)\n",
    "         if experiment\n",
    "         else os.path.join(\n",
    "            etl_dict['data_lake_path'], os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS'))))\n",
    "\n",
    "    model_name = (models_dict[experiment_name]['model_trainer']\n",
    "                  + os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS')\n",
    "                  + experiment_name+'.pkl'\n",
    "                  )\n",
    "\n",
    "    model = pull_sklearn_object_from_adls(\n",
    "        adls_path=os.path.join(adls_path,\n",
    "                               models_dict['modeling_adls_path'],\n",
    "                               models_dict[experiment_name]['model_trainer']\n",
    "                               ) + '/',\n",
    "        file_name=model_name,\n",
    "        drop_local_path='./models/',\n",
    "        container_name=etl_dict['azure_container'],\n",
    "        connection_str=os.environ[models_dict['connection_str']]\n",
    "    )\n",
    "\n",
    "    sf = snowflake_query()\n",
    "    df_infer = create_stage_and_query_stage_sf(\n",
    "        sf=sf,\n",
    "        etl=etl_dict,\n",
    "        udf_inputs=udf_inputs,\n",
    "        train_or_inference='INFERENCE',\n",
    "        experiment_name=experiment_name,\n",
    "        experiment=experiment,\n",
    "        indentification=models_dict['identification'],\n",
    "        extra_statement='LIMIT 1000'  # Can add limit when experimenting 'LIMIT 1000'\n",
    "    )\n",
    "    logging.info(f'size of test set {df_infer.shape}')\n",
    "    logging.info(f'Preview inference data:\\n{df_infer.head(2)}')\n",
    "    logging.info(f'Preview inference data values:\\n{df_infer.iloc[0].values}')\n",
    "\n",
    "    logging.info('Begining on inference upload process')\n",
    "    prediction_to_adls_and_sf(\n",
    "        df=df_infer,\n",
    "        sk_model_pipe=model,\n",
    "        adls_path=adls_path,\n",
    "        models_dict=models_dict,\n",
    "        etl_dict=etl_dict,\n",
    "        experiment_name=experiment_name,\n",
    "        sfSchema=sfSchema\n",
    "    )\n",
    "    logging.info(f'Inference stage complete for {experiment_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading Sklearn Object to: ./models/train_xgbLocalRunTestBASELINE.pkl\n",
      "INFO:data_system_utilities.azure.storage:Downloading projects/LTBP/FY23/experiments/BASELINE/modeling/train_xgb/train_xgbLocalRunTestBASELINE.pkl to ./models/train_xgbLocalRunTestBASELINE.pkl\n",
      "INFO:data_system_utilities.azure.storage:Download complete\n",
      "INFO:root:Sklearn Object Loaded\n",
      "INFO:data_system_utilities.snowflake.utils:stage_query: \n",
      " create or replace stage ltbpFY23LocalRunTest\n",
      "url='azure://vaildtscadls.blob.core.windows.net/vailadls/projects/LTBP/FY23/experiments/BASELINE'\n",
      "credentials=(azure_sas_token='**MASKED**')\n",
      "encryption=(type= 'NONE')\n",
      "file_format = (type = parquet        )\n",
      "INFO:data_system_utilities.snowflake.utils:connection to snowflake established...\n",
      "INFO:data_system_utilities.snowflake.query:executing query\n",
      "INFO:data_system_utilities.snowflake.query:data loaded from snowflake\n",
      "INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off\n",
      "INFO:data_system_utilities.snowflake.query:Stage area LTBPFY23LOCALRUNTEST successfully created.\n",
      "INFO:root:adls snowflake stage query \n",
      "    select\n",
      "    $1:\"ECID\"::varchar as ECID\n",
      ", $1:\"SEASONYEAR\"::varchar as SEASONYEAR\n",
      ", $1:\"AGE\"::varchar as AGE\n",
      ", $1:\"AVGVISITPERSEASON\"::varchar as AVGVISITPERSEASON\n",
      ", $1:\"BOUGHTPASS\"::varchar as BOUGHTPASS\n",
      ", $1:\"DESTINATIONGEOAFINITYLABEL\"::varchar as DESTINATIONGEOAFINITYLABEL\n",
      ", $1:\"EVERCOREPASS\"::varchar as EVERCOREPASS\n",
      ", $1:\"EVERPASS\"::varchar as EVERPASS\n",
      ", $1:\"GENDERCODE\"::varchar as GENDERCODE\n",
      ", $1:\"GUESTBEHAVIOR\"::varchar as GUESTBEHAVIOR\n",
      ", $1:\"ISEPICMIXACTIVATED\"::varchar as ISEPICMIXACTIVATED\n",
      ", $1:\"MARKETINGZONE\"::varchar as MARKETINGZONE\n",
      ", $1:\"MOSTCOMMONTICKETCOMP\"::varchar as MOSTCOMMONTICKETCOMP\n",
      ", $1:\"MOSTSUBSEASONVISITED\"::varchar as MOSTSUBSEASONVISITED\n",
      ", $1:\"MOSTVISITEDREGION\"::varchar as MOSTVISITEDREGION\n",
      ", $1:\"MOSTVISITEDRESORT\"::varchar as MOSTVISITEDRESORT\n",
      ", $1:\"ONLYSINGLERESORTKEY\"::varchar as ONLYSINGLERESORTKEY\n",
      ", $1:\"PARTNERRESORTSCANNERFLAG\"::varchar as PARTNERRESORTSCANNERFLAG\n",
      ", $1:\"RESORTSVISITED\"::varchar as RESORTSVISITED\n",
      ", $1:\"SKIERABILITYLABEL\"::varchar as SKIERABILITYLABEL\n",
      ", $1:\"SUBSEASONSPERYEAR\"::varchar as SUBSEASONSPERYEAR\n",
      ", $1:\"TOTALSEASONSSCANNED\"::varchar as TOTALSEASONSSCANNED\n",
      ", $1:\"TOTALVISITS\"::varchar as TOTALVISITS\n",
      ", $1:\"VISITMOSTINPEAK\"::varchar as VISITMOSTINPEAK\n",
      "\n",
      "    from @ltbpFY23LocalRunTest/inference_data/\n",
      "    LIMIT 1000\n",
      "    \n",
      "INFO:data_system_utilities.snowflake.utils:connection to snowflake established...\n",
      "INFO:data_system_utilities.snowflake.query:executing query\n",
      "INFO:data_system_utilities.snowflake.query:data loaded from snowflake\n",
      "INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off\n",
      "INFO:root:Preview dataframe queried        ECID SEASONYEAR AGE AVGVISITPERSEASON BOUGHTPASS  \\\n",
      "0  75277491    2021/22  54                 0          0   \n",
      "1  57932090    2021/22   4                 0          0   \n",
      "2  40834443    2021/22  14                 0          0   \n",
      "3  57631426    2021/22   4                 0          0   \n",
      "4  48415993    2021/22  53                 0          0   \n",
      "\n",
      "  DESTINATIONGEOAFINITYLABEL EVERCOREPASS EVERPASS GENDERCODE GUESTBEHAVIOR  \\\n",
      "0                Destination            0        0          F   Lapsed Paid   \n",
      "1                    Unknown            0        0          M   Lapsed Paid   \n",
      "2                    Unknown            0        0          F   Lapsed Paid   \n",
      "3                    Unknown            0        0          U   Lapsed Paid   \n",
      "4                Destination            0        0          F   Lapsed Paid   \n",
      "\n",
      "   ... MOSTVISITEDREGION MOSTVISITEDRESORT ONLYSINGLERESORTKEY  \\\n",
      "0  ...              None              None                None   \n",
      "1  ...              None              None                None   \n",
      "2  ...              None              None                None   \n",
      "3  ...              None              None                None   \n",
      "4  ...              None              None                None   \n",
      "\n",
      "  PARTNERRESORTSCANNERFLAG RESORTSVISITED SKIERABILITYLABEL SUBSEASONSPERYEAR  \\\n",
      "0                        0              0              None              None   \n",
      "1                        0              0              None              None   \n",
      "2                        0              0              None              None   \n",
      "3                        0              0              None              None   \n",
      "4                        0              0              None              None   \n",
      "\n",
      "  TOTALSEASONSSCANNED TOTALVISITS VISITMOSTINPEAK  \n",
      "0                   0           0               0  \n",
      "1                   0           0               0  \n",
      "2                   0           0               0  \n",
      "3                   0           0               0  \n",
      "4                   0           0               0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "INFO:root:size of test set (1000, 24)\n",
      "INFO:root:Preview inference data:\n",
      "       ECID SEASONYEAR AGE AVGVISITPERSEASON BOUGHTPASS  \\\n",
      "0  75277491    2021/22  54                 0          0   \n",
      "1  57932090    2021/22   4                 0          0   \n",
      "\n",
      "  DESTINATIONGEOAFINITYLABEL EVERCOREPASS EVERPASS GENDERCODE GUESTBEHAVIOR  \\\n",
      "0                Destination            0        0          F   Lapsed Paid   \n",
      "1                    Unknown            0        0          M   Lapsed Paid   \n",
      "\n",
      "   ... MOSTVISITEDREGION MOSTVISITEDRESORT ONLYSINGLERESORTKEY  \\\n",
      "0  ...              None              None                None   \n",
      "1  ...              None              None                None   \n",
      "\n",
      "  PARTNERRESORTSCANNERFLAG RESORTSVISITED SKIERABILITYLABEL SUBSEASONSPERYEAR  \\\n",
      "0                        0              0              None              None   \n",
      "1                        0              0              None              None   \n",
      "\n",
      "  TOTALSEASONSSCANNED TOTALVISITS VISITMOSTINPEAK  \n",
      "0                   0           0               0  \n",
      "1                   0           0               0  \n",
      "\n",
      "[2 rows x 24 columns]\n",
      "INFO:root:Preview inference data values:\n",
      "['75277491' '2021/22' '54' '0' '0' 'Destination' '0' '0' 'F' 'Lapsed Paid'\n",
      " None None None None None None None '0' '0' None None '0' '0' '0']\n",
      "INFO:root:Begining on inference upload process\n",
      "INFO:root:preview predictions being added:\n",
      "       ECID SEASONYEAR  PROBABILITY CI_COMMIT_SHA         DATE_CREATED  \\\n",
      "0  75277491    2021/22     0.100722  LocalRunTest  2022-11-02 18:15:18   \n",
      "1  57932090    2021/22     0.135460  LocalRunTest  2022-11-02 18:15:18   \n",
      "2  40834443    2021/22     0.117061  LocalRunTest  2022-11-02 18:15:18   \n",
      "\n",
      "  EXPERIMENT  \n",
      "0   BASELINE  \n",
      "1   BASELINE  \n",
      "2   BASELINE  \n",
      "INFO:root:preview predictions values addes:\n",
      "['75277491' '2021/22' 0.10072208 'LocalRunTest' '2022-11-02 18:15:18'\n",
      " 'BASELINE']\n",
      "INFO:root:preview predictions being added columns:\n",
      "Index(['ECID', 'SEASONYEAR', 'PROBABILITY', 'CI_COMMIT_SHA', 'DATE_CREATED',\n",
      "       'EXPERIMENT'],\n",
      "      dtype='object')\n",
      "INFO:data_system_utilities.azure.storage:Uploading predictions_LocalRunTestBASELINE.csv, to Azure Storage projects/LTBP/FY23/experiments/BASELINE/predictions/train_xgb/predictions_LocalRunTestBASELINE.csv\n",
      "INFO:data_system_utilities.azure.storage:Azure Upload Complete\n",
      "INFO:data_system_utilities.snowflake.utils:connection to snowflake established...\n",
      "INFO:data_system_utilities.snowflake.query:executing query\n",
      "INFO:data_system_utilities.snowflake.query:data loaded from snowflake\n",
      "INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off\n",
      "INFO:root:Pushing Forecasted Season from ADLS to Snowflake\n",
      "INFO:data_system_utilities.snowflake.copyinto:\n",
      "copy into MACHINELEARNINGOUTPUTS.DEV.LTBP_PREDICTIONS_FY23\n",
      "from 'azure://vaildtscadls.blob.core.windows.net/vailadls/projects/LTBP/FY23/experiments/BASELINE/predictions/train_xgb/predictions_LocalRunTestBASELINE.csv'\n",
      "file_format = (type = csv     skip_header = 1)\n",
      "credentials= (azure_sas_token = '?sv=2019-12-12&ss=bfqt&srt=sco&sp=rwdlacupx&se=2031-01-22T06:17:14Z&st=2021-01-21T22:17:14Z&spr=https&sig=kIHogByJjyVWyL6XupA0CBUB1iw12%2FeXWFQiOj5fB5c%3D')\n",
      "pattern = '.*.csv';\n",
      "INFO:data_system_utilities.snowflake.utils:connection to snowflake established...\n",
      "INFO:data_system_utilities.snowflake.query:executing query\n",
      "INFO:data_system_utilities.snowflake.query:data loaded from snowflake\n",
      "INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_system_utilities.snowflake.utils:connection to snowflake established...\n",
      "INFO:data_system_utilities.snowflake.query:executing query\n",
      "INFO:data_system_utilities.snowflake.query:data loaded from snowflake\n",
      "INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off\n",
      "INFO:root:preview of queried table being added:\n",
      "       ECID SEASONYEAR  PROBABILITY CI_COMMIT_SHA         DATE_CREATED  \\\n",
      "0  75277491    2021/22     0.100722  LocalRunTest  2022-11-02 18:15:18   \n",
      "1  57932090    2021/22     0.135460  LocalRunTest  2022-11-02 18:15:18   \n",
      "2  40834443    2021/22     0.117061  LocalRunTest  2022-11-02 18:15:18   \n",
      "\n",
      "  EXPERIMENT  \n",
      "0   BASELINE  \n",
      "1   BASELINE  \n",
      "2   BASELINE  \n",
      "INFO:root:preview predictions values addes:\n",
      "['75277491' '2021/22' 0.10072208 'LocalRunTest' '2022-11-02 18:15:18'\n",
      " 'BASELINE']\n",
      "INFO:root:Inference stage complete for BASELINE\n"
     ]
    }
   ],
   "source": [
    "#| skip\n",
    "experiment_name = 'BASELINE'\n",
    "experiment = True\n",
    "yaml_file_list = ['features.yaml', 'udf_inputs.yaml', 'etl.yaml', 'models.yaml']\n",
    "features, udf_inputs, etl_dict, models_dict = get_yaml_dicts(yaml_file_list)\n",
    "adls_path = os.path.join(\n",
    "    (os.path.join(etl_dict['data_lake_path'], 'experiments', experiment_name)\n",
    "      if experiment\n",
    "      else os.path.join(\n",
    "          etl_dict['data_lake_path'], os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS'))))\n",
    "\n",
    "model_name = (models_dict[experiment_name]['model_trainer']+\n",
    "              os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS')+\n",
    "              experiment_name+'.pkl'\n",
    "             )\n",
    "\n",
    "model = pull_sklearn_object_from_adls(\n",
    "        adls_path=os.path.join(adls_path,\n",
    "                               models_dict['modeling_adls_path'],\n",
    "                               models_dict[experiment_name]['model_trainer']\n",
    "                              ) + '/',\n",
    "        file_name=model_name,\n",
    "        drop_local_path='./models/',\n",
    "        container_name=etl_dict['azure_container'],\n",
    "        connection_str=os.environ[models_dict['connection_str']]\n",
    "    )\n",
    "\n",
    "sf = snowflake_query()\n",
    "df_infer = create_stage_and_query_stage_sf(\n",
    "    sf=sf,\n",
    "    etl=etl_dict,\n",
    "    udf_inputs=udf_inputs,\n",
    "    train_or_inference='INFERENCE',\n",
    "    experiment_name=experiment_name,\n",
    "    experiment=experiment,\n",
    "    indentification=models_dict['identification'],\n",
    "    extra_statement='LIMIT 1000'\n",
    ")\n",
    "logging.info(f'size of test set {df_infer.shape}')\n",
    "logging.info(f'Preview inference data:\\n{df_infer.head(2)}')\n",
    "logging.info(f'Preview inference data values:\\n{df_infer.iloc[0].values}')\n",
    "\n",
    "logging.info('Begining on inference upload process')\n",
    "prediction_to_adls_and_sf(\n",
    "    df=df_infer,\n",
    "    sk_model_pipe=model,\n",
    "    adls_path=adls_path,\n",
    "    models_dict=models_dict,\n",
    "    etl_dict=etl_dict,\n",
    "    experiment_name=experiment_name,\n",
    "    sfSchema=os.getenv(\"sfSchema\", \"DEV\")\n",
    ")\n",
    "logging.info(f'Inference stage complete for {experiment_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
