{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Models Available For This Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp scripts.modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremydemlow/miniforge3/envs/ltbp/lib/python3.9/site-packages/snowflake/connector/options.py:96: UserWarning: You have an incompatible version of 'pyarrow' installed (6.0.0), please install a version that adheres to: 'pyarrow<8.1.0,>=8.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "from fastcore.script import Param, call_parse\n",
    "\n",
    "from sklearn import preprocessing as processors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from LTBP.data.utils import snowflake_query, get_yaml_dicts, generate_data_lake_query\n",
    "from LTBP.modeling.utils import (\n",
    "    create_stage_and_query_stage_sf, create_sklearn_preprocess_baseline_dict, \n",
    "    return_list_of_vars, prepare_training_set\n",
    ")\n",
    "from LTBP.modeling.custom_utils import evaluate\n",
    "from LTBP import files\n",
    "\n",
    "from machine_learning_utilities import preprocessing\n",
    "\n",
    "from data_system_utilities.file_parsers import yaml\n",
    "from data_system_utilities.snowflake.utils import make_stage_query_generator\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing as processors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import LTBP.modeling.models as ds_models\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from pathlib import Path\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def write_yaml_file(file_path: str, file_name: str, dictionary: dict):\n",
    "    with open(Path(file_path, file_name), 'w') as f:\n",
    "        yaml.dump(dictionary, f)\n",
    "\n",
    "models = dict({\n",
    "    'preprocessors_adls_path' : 'preprocessors/',\n",
    "    'connection_str': 'DATALAKE_CONN_STR_SECRET',\n",
    "    'hold_out_table' : 'LTBP_HOLDOUT_TEST_MODEL_RESULTS',\n",
    "    'tracking_table' : 'LTBP_MODEL_TRACKING_FY23',\n",
    "    'idenfication': ['ECID', 'SEASONYEAR'],\n",
    "    'BASELINE': {\n",
    "        'description': 'Standard baseline xgb_hyperopt approach status quo of LTBP of the past',\n",
    "        'model_trainer': 'train_xgb',\n",
    "        'y_preprocess_object_name': None,\n",
    "        'y_scaler_type' : None,\n",
    "        'x_preprocess_object_name': 'standard_pipe.pickle'\n",
    "\n",
    "    },\n",
    "    'NOHYPEROPT': {\n",
    "        'description': 'Only here to see if it works delete at some point xgb_fit_only',\n",
    "        'model_trainer': 'train_xgb_basic',\n",
    "        'y_preprocess_object_name': None,\n",
    "        'y_scaler_type' : None,\n",
    "        'x_preprocess_object_name': 'standard_pipe.pickle'\n",
    "    }\n",
    "})\n",
    "\n",
    "write_yaml_file('./LTBP/files/yaml_files/', 'models.yaml', models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the DSDE standard process for using Xboost with hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def model_train(yaml_file_list: Param(help=\"YAML files to read\", type=list, # noqa:\n",
    "                                      default=['dataset.yaml', 'etl.yaml', 'experiment.yaml']),  # noqa:\n",
    "                hyper_sub_size: Param(help=\"\", type=int, default=2750000),  # noqa:\n",
    "                train_size: Param(help=\"\", type=int, default=5500000),  # noqa:\n",
    "                evals: Param(help=\"logit threshold cut\", type=int, default=10),  # noqa:\n",
    "                train_model: Param(help=\"to subsample or not\", type=str, default='True'),  # noqa:\n",
    "                fit_only: Param(help=\"no tuning model training\", type=str, default='False')):  # noqa:\n",
    "    \n",
    "    features, udf_inputs, etl, models = get_yaml_dicts(['features.yaml', 'udf_inputs.yaml', 'etl.yaml', 'models.yaml'])\n",
    "    df = create_stage_and_query_stage_sf(\n",
    "        sf=sf,\n",
    "        etl=etl,\n",
    "        udf_inputs=udf_inputs,\n",
    "        train_or_inference=train_or_inference,\n",
    "        experiment_name=experiment_name,\n",
    "        experiment=experiment,\n",
    "        indentification=models['idenfication']\n",
    "        )\n",
    "\n",
    "    cat_vars =[{f.upper() : values['transformation'][experiment_name]} for f, values in features.items() \n",
    "                if values['var_type'][experiment_name] == 'cat'\n",
    "                and values['input_definition'] != 'LABEL']\n",
    "    cont_vars =[{f.upper(): values['transformation'][experiment_name]} for f, values in features.items() \n",
    "                if values['var_type'][experiment_name] == 'cont'\n",
    "                and values['input_definition'] != 'LABEL']\n",
    "\n",
    "    feature_dict = create_sklearn_preprocess_baseline_dict(cat_vars=cat_vars, \n",
    "                                                           cont_vars=cont_vars)\n",
    "    logging.info(feature_dict)\n",
    "    cat_vars = return_list_of_vars(cat_vars)\n",
    "    cont_vars = return_list_of_vars(cont_vars)\n",
    "    logging.info(f\"categorical variables: \\n {cat_vars}\")\n",
    "    logging.info(f\"continous variables: \\n {cont_vars}\")\n",
    "\n",
    "    pipe = preprocessing.generate_sklearn_preprocessing_pipeline(\n",
    "        feature_dict, impute=True, impute_strategy='mean'\n",
    "    )\n",
    "\n",
    "    adls_path = os.path.join((os.path.join(etl['data_lake_path'], 'experiments', experiment_name)\n",
    "        if experiment \n",
    "        else os.path.join(etl_dict['data_lake_path'], \n",
    "        os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS')))\n",
    "        , models['preprocessors_adls_path'])\n",
    "\n",
    "    y_var=[k.upper() for k, v in features.items() if v['input_definition'] == 'LABEL']\n",
    "\n",
    "    result = prepare_training_set(df,\n",
    "                                  y_var=[k.upper() for k, v in features.items() if v['input_definition'] == 'LABEL'],\n",
    "                                  y_scaler_type=models[experiment_name]['y_scaler_type'],\n",
    "                                  adls_path=adls_path,\n",
    "                                  sklearn_pipe=pipe,\n",
    "                                  test_set=True,\n",
    "                                  etl_dict=etl,\n",
    "                                  models_dict=models,\n",
    "                                  connection_str=os.environ[models[\"connection_str\"]],\n",
    "                                  experiment_name=experiment_name,\n",
    "                                  as_type=int,\n",
    "                                  identifiers=['ECID', 'SEASONYEAR']\n",
    "                                  )\n",
    "    if test_set:\n",
    "        X_train, X_valid, X_test, y_train, y_valid, y_test, sklearn_pipe, scaler, id_list = result\n",
    "    else:\n",
    "        X_train, X_valid, y_train, y_valid, sklearn_pipe, scaler, id_list = result\n",
    "\n",
    "    model_trainer = getattr(ds_models, models[experiment_name]['model_trainer'])\n",
    "\n",
    "    cat_vars =[{f.upper() : values['transformation'][experiment_name]} for f, values in features.items() \n",
    "                if values['var_type'][experiment_name] == 'cat'\n",
    "                and values['input_definition'] != 'LABEL']\n",
    "    cont_vars =[{f.upper(): values['transformation'][experiment_name]} for f, values in features.items() \n",
    "                if values['var_type'][experiment_name] == 'cont'\n",
    "                and values['input_definition'] != 'LABEL']\n",
    "\n",
    "    feature_dict = create_sklearn_preprocess_baseline_dict(cat_vars=cat_vars, \n",
    "                                                           cont_vars=cont_vars)\n",
    "    logging.info(feature_dict)\n",
    "    cat_vars = return_list_of_vars(cat_vars)\n",
    "    cont_vars = return_list_of_vars(cont_vars)\n",
    "    logging.info(f\"categorical variables: \\n {cat_vars}\")\n",
    "    logging.info(f\"continous variables: \\n {cont_vars}\")\n",
    "\n",
    "    pipe = preprocessing.generate_sklearn_preprocessing_pipeline(\n",
    "        feature_dict, impute=True, impute_strategy='mean'\n",
    "    )\n",
    "\n",
    "    adls_path = os.path.join((os.path.join(etl['data_lake_path'], 'experiments', experiment_name)\n",
    "        if experiment\n",
    "        else os.path.join(etl_dict['data_lake_path'],\n",
    "        os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS')))\n",
    "        , models['preprocessors_adls_path'])\n",
    "\n",
    "    model = model_trainer(X_train, X_valid, y_train, y_valid,\n",
    "        evals=evals, sub=hyper_sub_size, train=train_size)\n",
    "\n",
    "    y_var=[k.upper() for k, v in features.items() if v['input_definition'] == 'LABEL']\n",
    "\n",
    "    \"\"\"\n",
    "    Custom needs for each project type this works for a binary classification\n",
    "    this is not my best work, but trying to put something together \n",
    "    this is dry I am sure i could make this just a few lines \n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "    logging.info('Training Set Evaluation')\n",
    "\n",
    "    eval_list_train = evaluate(model, X_train, y_train, y_var, feature_importance=True)\n",
    "    metric1, metric2, metric3, columns, fi_permutation = eval_list_train\n",
    "    result_dict['training_metrics']={k: v for k, v in zip(columns, [metric1]+[metric2]+[metric3])}\n",
    "    result_dict['fi_train']={k:v for k, v in fi_permutation[:10].values}\n",
    "    logging.info('Validation Set Evaluation')\n",
    "    eval_list_valid = evaluate(model, X_valid, y_valid, y_var, feature_importance=True)\n",
    "    metric1, metric2, metric3, columns, fi_permutation = eval_list_train\n",
    "    result_dict['valid_metrics']={k: v for k, v in zip(columns, [metric1]+[metric2]+[metric3])}\n",
    "    result_dict['fi_valid']={k:v for k, v in fi_permutation[:10].values}\n",
    "    if X_test is not None:\n",
    "        logging.info('Test Set Evaluation')\n",
    "        eval_list_test = evaluate(model, X_test, y_test, y_var, feature_importance=True)\n",
    "        metric1, metric2, metric3, columns, fi_permutation = eval_list_train\n",
    "        result_dict['test_metrics']={k: v for k, v in zip(columns, [metric1]+[metric2]+[metric3])}\n",
    "        result_dict['fi_test']={k:v for k, v in fi_permutation[:10].values}\n",
    "\n",
    "    sf = snowflake_query(sfSchema='LTBP')\n",
    "    send_holdout_results_to_sf(sf, id_list, y_pred_proba, experiment, experiment_name, etl, models)\n",
    "\n",
    "    adls_path = os.path.join((os.path.join(etl['data_lake_path'], 'experiments', experiment_name)\n",
    "        if experiment \n",
    "        else os.path.join(etl_dict['data_lake_path'], \n",
    "        os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS'))))\n",
    "\n",
    "    project_log_df = project_log.project_log(\n",
    "        snowflake_connection=sf,\n",
    "        table_name=models['tracking_table'],\n",
    "        action_description=models[experiment_name][\"description\"],\n",
    "        transaction_type=\"model_training\",\n",
    "        artifacts=json.dumps({\"azure_parent_folder\": adls_path}),\n",
    "        metrics=json.dumps(result_dict),\n",
    "        append_or_replace=\"append\",\n",
    "    )\n",
    "    logging.info(f'project log preview:\\n{project_log_df.head(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = True # this will trigger if the feature set needs to be created\n",
    "train_or_inference = 'TRAINING' # 'INFERENCE'\n",
    "experiment_name='BASELINE'\n",
    "sf = snowflake_query()\n",
    "\n",
    "scaler_type = getattr(processors, 'LabelEncoder')() # Don't actuall use this with a binaryclass\n",
    "scaler_type = None\n",
    "y_var='BOUGHTPASS'\n",
    "test_set=True\n",
    "connection_str = os.environ['DATALAKE_CONN_STR_SECRET']\n",
    "experiment_name='BASELINE'\n",
    "\n",
    "evals=2\n",
    "hyper_sub_size=200000\n",
    "train_size=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_system_utilities.snowflake.utils:stage_query: \n",
      " create or replace stage ltbpFY23LocalRunTest\n",
      "url='azure://vaildtscadls.blob.core.windows.net/vailadls/projects/LTBP/FY23/experiments/BASELINE'\n",
      "credentials=(azure_sas_token='**MASKED**')\n",
      "encryption=(type= 'NONE')\n",
      "file_format = (type = parquet        )\n",
      "INFO:data_system_utilities.snowflake.utils:connection to snowflake established...\n",
      "INFO:data_system_utilities.snowflake.query:executing query\n",
      "INFO:data_system_utilities.snowflake.query:data loaded from snowflake\n",
      "INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off\n",
      "INFO:data_system_utilities.snowflake.query:Stage area LTBPFY23LOCALRUNTEST successfully created.\n",
      "INFO:root:adls snowflake stage query \n",
      "    select\n",
      "    $1:\"ECID\"::varchar as ECID\n",
      ", $1:\"SEASONYEAR\"::varchar as SEASONYEAR\n",
      ", $1:\"AGE\"::varchar as AGE\n",
      ", $1:\"AVGVISITPERSEASON\"::varchar as AVGVISITPERSEASON\n",
      ", $1:\"BOUGHTPASS\"::varchar as BOUGHTPASS\n",
      ", $1:\"DESTINATIONGEOAFINITYLABEL\"::varchar as DESTINATIONGEOAFINITYLABEL\n",
      ", $1:\"EVERCOREPASS\"::varchar as EVERCOREPASS\n",
      ", $1:\"EVERPASS\"::varchar as EVERPASS\n",
      ", $1:\"GENDERCODE\"::varchar as GENDERCODE\n",
      ", $1:\"GUESTBEHAVIOR\"::varchar as GUESTBEHAVIOR\n",
      ", $1:\"ISEPICMIXACTIVATED\"::varchar as ISEPICMIXACTIVATED\n",
      ", $1:\"MARKETINGZONE\"::varchar as MARKETINGZONE\n",
      ", $1:\"MOSTCOMMONTICKETCOMP\"::varchar as MOSTCOMMONTICKETCOMP\n",
      ", $1:\"MOSTSUBSEASONVISITED\"::varchar as MOSTSUBSEASONVISITED\n",
      ", $1:\"MOSTVISITEDREGION\"::varchar as MOSTVISITEDREGION\n",
      ", $1:\"MOSTVISITEDRESORT\"::varchar as MOSTVISITEDRESORT\n",
      ", $1:\"ONLYSINGLERESORTKEY\"::varchar as ONLYSINGLERESORTKEY\n",
      ", $1:\"PARTNERRESORTSCANNERFLAG\"::varchar as PARTNERRESORTSCANNERFLAG\n",
      ", $1:\"RESORTSVISITED\"::varchar as RESORTSVISITED\n",
      ", $1:\"SKIERABILITYLABEL\"::varchar as SKIERABILITYLABEL\n",
      ", $1:\"SUBSEASONSPERYEAR\"::varchar as SUBSEASONSPERYEAR\n",
      ", $1:\"TOTALSEASONSSCANNED\"::varchar as TOTALSEASONSSCANNED\n",
      ", $1:\"TOTALVISITS\"::varchar as TOTALVISITS\n",
      ", $1:\"VISITMOSTINPEAK\"::varchar as VISITMOSTINPEAK\n",
      "\n",
      "    from @ltbpFY23LocalRunTest/training_data/\n",
      "    None\n",
      "    \n",
      "INFO:data_system_utilities.snowflake.utils:connection to snowflake established...\n",
      "INFO:data_system_utilities.snowflake.query:executing query\n",
      "INFO:data_system_utilities.snowflake.query:data loaded from snowflake\n",
      "INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off\n",
      "INFO:root:Preview dataframe queried        ECID SEASONYEAR AGE AVGVISITPERSEASON BOUGHTPASS  \\\n",
      "0  54902629    2018/19  43                 6          1   \n",
      "1  84336209    2018/19  36                12          1   \n",
      "2  40806345    2018/19  44               4.5          1   \n",
      "3  26609174    2018/19  10                 3          0   \n",
      "4  46910534    2018/19  14                16          1   \n",
      "\n",
      "  DESTINATIONGEOAFINITYLABEL EVERCOREPASS EVERPASS GENDERCODE  \\\n",
      "0                      Local            0        1          U   \n",
      "1              International            1        1          M   \n",
      "2                Destination            0        1          F   \n",
      "3                Destination            0        0          M   \n",
      "4                Destination            1        1          M   \n",
      "\n",
      "        GUESTBEHAVIOR  ...  MOSTVISITEDREGION MOSTVISITEDRESORT  \\\n",
      "0  Renewal Multi-Year  ...  Pacific Northwest                18   \n",
      "1                None  ...  Pacific Northwest                18   \n",
      "2  Renewal Multi-Year  ...     Rocky Mountain                 1   \n",
      "3             PY Paid  ...     Rocky Mountain                 3   \n",
      "4  Renewal Multi-Year  ...     Rocky Mountain                 3   \n",
      "\n",
      "  ONLYSINGLERESORTKEY PARTNERRESORTSCANNERFLAG RESORTSVISITED  \\\n",
      "0                  18                        0              2   \n",
      "1                  18                        0              1   \n",
      "2                None                        0              2   \n",
      "3                   3                        0              1   \n",
      "4                None                        0              1   \n",
      "\n",
      "   SKIERABILITYLABEL SUBSEASONSPERYEAR TOTALSEASONSSCANNED TOTALVISITS  \\\n",
      "0       Intermediate               4.5                   2          12   \n",
      "1               None                 3                   1          12   \n",
      "2           Advanced                 1                   2           9   \n",
      "3  Advanced-Beginner                 1                   1           3   \n",
      "4           Advanced                 4                   2          32   \n",
      "\n",
      "  VISITMOSTINPEAK  \n",
      "0               0  \n",
      "1               0  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "INFO:root:{'DESTINATIONGEOAFINITYLABEL': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'EVERCOREPASS': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'EVERPASS': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'GENDERCODE': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'GUESTBEHAVIOR': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'ISEPICMIXACTIVATED': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'MARKETINGZONE': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'MOSTCOMMONTICKETCOMP': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'MOSTSUBSEASONVISITED': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'MOSTVISITEDREGION': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'MOSTVISITEDRESORT': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'ONLYSINGLERESORTKEY': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'PARTNERRESORTSCANNERFLAG': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'SKIERABILITYLABEL': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'TOTALSEASONSSCANNED': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'VISITMOSTINPEAK': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'AGE': {'transformation': {'name': 'StandardScaler', 'args': {}}, 'variable_type': 'cont'}, 'AVGVISITPERSEASON': {'transformation': {'name': 'StandardScaler', 'args': {}}, 'variable_type': 'cont'}, 'RESORTSVISITED': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'SUBSEASONSPERYEAR': {'transformation': {'name': 'StandardScaler', 'args': {}}, 'variable_type': 'cont'}, 'TOTALVISITS': {'transformation': {'name': 'StandardScaler', 'args': {}}, 'variable_type': 'cont'}}\n",
      "INFO:root:categorical variables: \n",
      " ['DESTINATIONGEOAFINITYLABEL', 'EVERCOREPASS', 'EVERPASS', 'GENDERCODE', 'GUESTBEHAVIOR', 'ISEPICMIXACTIVATED', 'MARKETINGZONE', 'MOSTCOMMONTICKETCOMP', 'MOSTSUBSEASONVISITED', 'MOSTVISITEDREGION', 'MOSTVISITEDRESORT', 'ONLYSINGLERESORTKEY', 'PARTNERRESORTSCANNERFLAG', 'SKIERABILITYLABEL', 'TOTALSEASONSSCANNED', 'VISITMOSTINPEAK']\n",
      "INFO:root:continous variables: \n",
      " ['AGE', 'AVGVISITPERSEASON', 'RESORTSVISITED', 'SUBSEASONSPERYEAR', 'TOTALVISITS']\n",
      "INFO:machine_learning_utilities.preprocessing:Creating Sklearn Preprocessing Pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:machine_learning_utilities.preprocessing:Feature: DESTINATIONGEOAFINITYLABEL --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: EVERCOREPASS --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: EVERPASS --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: GENDERCODE --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: GUESTBEHAVIOR --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: ISEPICMIXACTIVATED --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: MARKETINGZONE --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: MOSTCOMMONTICKETCOMP --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: MOSTSUBSEASONVISITED --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: MOSTVISITEDREGION --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: MOSTVISITEDRESORT --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: ONLYSINGLERESORTKEY --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: PARTNERRESORTSCANNERFLAG --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: SKIERABILITYLABEL --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: TOTALSEASONSSCANNED --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: VISITMOSTINPEAK --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: AGE --> Transformer: StandardScaler()\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: AVGVISITPERSEASON --> Transformer: StandardScaler()\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: RESORTSVISITED --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: SUBSEASONSPERYEAR --> Transformer: StandardScaler()\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: TOTALVISITS --> Transformer: StandardScaler()\n",
      "INFO:machine_learning_utilities.preprocessing:Imputing missing data with mean strategy\n",
      "INFO:machine_learning_utilities.preprocessing:Preprocessing Pipeline Object:\n",
      "Pipeline(steps=[('preprocessing',\n",
      "                 FeatureUnion(transformer_list=[('pipeline-1',\n",
      "                                                 Pipeline(steps=[('functiontransformer',\n",
      "                                                                  FunctionTransformer(func=<function get_cat_cols>,\n",
      "                                                                                      kw_args={'cols': ['DESTINATIONGEOAFINITYLABEL']})),\n",
      "                                                                 ('ordinalencoder',\n",
      "                                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n",
      "                                                                                 unknown_value=-1))])),\n",
      "                                                ('pipeline-2',\n",
      "                                                 Pipeline(steps=[('...\n",
      "                                                                  FunctionTransformer(func=<function get_cont_cols>,\n",
      "                                                                                      kw_args={'cols': ['SUBSEASONSPERYEAR']})),\n",
      "                                                                 ('standardscaler',\n",
      "                                                                  StandardScaler())])),\n",
      "                                                ('pipeline-21',\n",
      "                                                 Pipeline(steps=[('functiontransformer',\n",
      "                                                                  FunctionTransformer(func=<function get_cont_cols>,\n",
      "                                                                                      kw_args={'cols': ['TOTALVISITS']})),\n",
      "                                                                 ('standardscaler',\n",
      "                                                                  StandardScaler())]))])),\n",
      "                ('imputing', SimpleImputer())])\n",
      "INFO:root:Successfully Spilt Data\n",
      "Train: (24000, 24), (24000, 1)\n",
      "Valid: (5100, 24), (5100, 1)\n",
      "Test: (900, 24), (900, 1)\n",
      "INFO:root:This project relies on the query to have accurate labels with no preprocessing..\n",
      "INFO:root:Pushing Sklearn Object to Azure: projects/LTBP/FY23/experiments/BASELINE/preprocessors/standard_pipe.pickle\n",
      "INFO:data_system_utilities.azure.storage:Uploading standard_pipe.pickle, to Azure Storage projects/LTBP/FY23/experiments/BASELINE/preprocessors/standard_pipe.pickle\n",
      "INFO:data_system_utilities.azure.storage:Azure Upload Complete\n",
      "INFO:root:standard_pipe.pickle successfully pushed to projects/LTBP/FY23/experiments/BASELINE/preprocessors/\n",
      "INFO:root:{'DESTINATIONGEOAFINITYLABEL': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'EVERCOREPASS': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'EVERPASS': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'GENDERCODE': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'GUESTBEHAVIOR': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'ISEPICMIXACTIVATED': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'MARKETINGZONE': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'MOSTCOMMONTICKETCOMP': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'MOSTSUBSEASONVISITED': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'MOSTVISITEDREGION': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'MOSTVISITEDRESORT': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'ONLYSINGLERESORTKEY': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'PARTNERRESORTSCANNERFLAG': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'SKIERABILITYLABEL': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'TOTALSEASONSSCANNED': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'VISITMOSTINPEAK': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'AGE': {'transformation': {'name': 'StandardScaler', 'args': {}}, 'variable_type': 'cont'}, 'AVGVISITPERSEASON': {'transformation': {'name': 'StandardScaler', 'args': {}}, 'variable_type': 'cont'}, 'RESORTSVISITED': {'transformation': {'name': 'OrdinalEncoder', 'args': {'handle_unknown': 'use_encoded_value', 'unknown_value': -1}}, 'variable_type': 'cat'}, 'SUBSEASONSPERYEAR': {'transformation': {'name': 'StandardScaler', 'args': {}}, 'variable_type': 'cont'}, 'TOTALVISITS': {'transformation': {'name': 'StandardScaler', 'args': {}}, 'variable_type': 'cont'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:categorical variables: \n",
      " ['DESTINATIONGEOAFINITYLABEL', 'EVERCOREPASS', 'EVERPASS', 'GENDERCODE', 'GUESTBEHAVIOR', 'ISEPICMIXACTIVATED', 'MARKETINGZONE', 'MOSTCOMMONTICKETCOMP', 'MOSTSUBSEASONVISITED', 'MOSTVISITEDREGION', 'MOSTVISITEDRESORT', 'ONLYSINGLERESORTKEY', 'PARTNERRESORTSCANNERFLAG', 'SKIERABILITYLABEL', 'TOTALSEASONSSCANNED', 'VISITMOSTINPEAK']\n",
      "INFO:root:continous variables: \n",
      " ['AGE', 'AVGVISITPERSEASON', 'RESORTSVISITED', 'SUBSEASONSPERYEAR', 'TOTALVISITS']\n",
      "INFO:machine_learning_utilities.preprocessing:Creating Sklearn Preprocessing Pipeline\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: DESTINATIONGEOAFINITYLABEL --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: EVERCOREPASS --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: EVERPASS --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: GENDERCODE --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: GUESTBEHAVIOR --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: ISEPICMIXACTIVATED --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: MARKETINGZONE --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: MOSTCOMMONTICKETCOMP --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: MOSTSUBSEASONVISITED --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: MOSTVISITEDREGION --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: MOSTVISITEDRESORT --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: ONLYSINGLERESORTKEY --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: PARTNERRESORTSCANNERFLAG --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: SKIERABILITYLABEL --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: TOTALSEASONSSCANNED --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: VISITMOSTINPEAK --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: AGE --> Transformer: StandardScaler()\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: AVGVISITPERSEASON --> Transformer: StandardScaler()\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: RESORTSVISITED --> Transformer: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: SUBSEASONSPERYEAR --> Transformer: StandardScaler()\n",
      "INFO:machine_learning_utilities.preprocessing:Feature: TOTALVISITS --> Transformer: StandardScaler()\n",
      "INFO:machine_learning_utilities.preprocessing:Imputing missing data with mean strategy\n",
      "INFO:machine_learning_utilities.preprocessing:Preprocessing Pipeline Object:\n",
      "Pipeline(steps=[('preprocessing',\n",
      "                 FeatureUnion(transformer_list=[('pipeline-1',\n",
      "                                                 Pipeline(steps=[('functiontransformer',\n",
      "                                                                  FunctionTransformer(func=<function get_cat_cols>,\n",
      "                                                                                      kw_args={'cols': ['DESTINATIONGEOAFINITYLABEL']})),\n",
      "                                                                 ('ordinalencoder',\n",
      "                                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n",
      "                                                                                 unknown_value=-1))])),\n",
      "                                                ('pipeline-2',\n",
      "                                                 Pipeline(steps=[('...\n",
      "                                                                  FunctionTransformer(func=<function get_cont_cols>,\n",
      "                                                                                      kw_args={'cols': ['SUBSEASONSPERYEAR']})),\n",
      "                                                                 ('standardscaler',\n",
      "                                                                  StandardScaler())])),\n",
      "                                                ('pipeline-21',\n",
      "                                                 Pipeline(steps=[('functiontransformer',\n",
      "                                                                  FunctionTransformer(func=<function get_cont_cols>,\n",
      "                                                                                      kw_args={'cols': ['TOTALVISITS']})),\n",
      "                                                                 ('standardscaler',\n",
      "                                                                  StandardScaler())]))])),\n",
      "                ('imputing', SimpleImputer())])\n",
      "INFO:root:Hyper tuning on 24000 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                       | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.008663 seconds\n",
      "INFO:hyperopt.tpe:TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|▌| 1/2 [00:00<00:00,  1.42trial/s, best loss: 0.1156746118111"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.007475 seconds\n",
      "INFO:hyperopt.tpe:TPE using 1/1 trials with best loss 0.115675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█| 2/2 [00:06<00:00,  3.15s/trial, best loss: 0.0923767434141"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Full training on 10000 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training Set Evaluation\n",
      "INFO:root:Variable(s) of interest ['BOUGHTPASS'] AUC: 0.919    Accuracy: 0.846    Balanced Accuracy: 0.847\n",
      "INFO:root:Feature Importance df: \n",
      "                           COLS     IMP\n",
      "0                     EVERPASS  0.1740\n",
      "1         MOSTCOMMONTICKETCOMP  0.0260\n",
      "2            SUBSEASONSPERYEAR  0.0186\n",
      "3                          AGE  0.0172\n",
      "4                GUESTBEHAVIOR  0.0164\n",
      "5                  TOTALVISITS  0.0162\n",
      "6                 EVERCOREPASS  0.0152\n",
      "7         MOSTSUBSEASONVISITED  0.0116\n",
      "8            MOSTVISITEDRESORT  0.0086\n",
      "9   DESTINATIONGEOAFINITYLABEL  0.0080\n",
      "10           MOSTVISITEDREGION  0.0068\n",
      "11         ONLYSINGLERESORTKEY  0.0054\n",
      "12          ISEPICMIXACTIVATED  0.0050\n",
      "13              RESORTSVISITED  0.0044\n",
      "14           SKIERABILITYLABEL  0.0042\n",
      "15               MARKETINGZONE  0.0034\n",
      "16           AVGVISITPERSEASON  0.0034\n",
      "17         TOTALSEASONSSCANNED  0.0018\n",
      "18             VISITMOSTINPEAK  0.0016\n",
      "19                  GENDERCODE  0.0010\n",
      "20    PARTNERRESORTSCANNERFLAG  0.0002\n",
      "INFO:root:Validation Set Evaluation\n",
      "INFO:root:Variable(s) of interest ['BOUGHTPASS'] AUC: 0.905    Accuracy: 0.826    Balanced Accuracy: 0.826\n",
      "INFO:root:Feature Importance df: \n",
      "                           COLS     IMP\n",
      "0                     EVERPASS  0.1632\n",
      "1         MOSTCOMMONTICKETCOMP  0.0142\n",
      "2   DESTINATIONGEOAFINITYLABEL  0.0088\n",
      "3            SUBSEASONSPERYEAR  0.0082\n",
      "4                          AGE  0.0072\n",
      "5                 EVERCOREPASS  0.0070\n",
      "6                  TOTALVISITS  0.0042\n",
      "7            SKIERABILITYLABEL  0.0028\n",
      "8            MOSTVISITEDRESORT  0.0002\n",
      "9           ISEPICMIXACTIVATED -0.0008\n",
      "10    PARTNERRESORTSCANNERFLAG -0.0010\n",
      "11               MARKETINGZONE -0.0014\n",
      "12        MOSTSUBSEASONVISITED -0.0016\n",
      "13         TOTALSEASONSSCANNED -0.0016\n",
      "14         ONLYSINGLERESORTKEY -0.0022\n",
      "15              RESORTSVISITED -0.0024\n",
      "16             VISITMOSTINPEAK -0.0028\n",
      "17                  GENDERCODE -0.0028\n",
      "18           AVGVISITPERSEASON -0.0030\n",
      "19               GUESTBEHAVIOR -0.0038\n",
      "20           MOSTVISITEDREGION -0.0040\n",
      "INFO:root:Test Set Evaluation\n",
      "INFO:root:Variable(s) of interest ['BOUGHTPASS'] AUC: 0.905    Accuracy: 0.832    Balanced Accuracy: 0.829\n",
      "INFO:root:Feature Importance df: \n",
      "                           COLS       IMP\n",
      "0                     EVERPASS  0.162222\n",
      "1            SUBSEASONSPERYEAR  0.030000\n",
      "2         MOSTCOMMONTICKETCOMP  0.020000\n",
      "3                 EVERCOREPASS  0.020000\n",
      "4            MOSTVISITEDREGION  0.008889\n",
      "5            AVGVISITPERSEASON  0.008889\n",
      "6           ISEPICMIXACTIVATED  0.007778\n",
      "7                MARKETINGZONE  0.007778\n",
      "8              VISITMOSTINPEAK  0.003333\n",
      "9         MOSTSUBSEASONVISITED  0.003333\n",
      "10    PARTNERRESORTSCANNERFLAG  0.003333\n",
      "11  DESTINATIONGEOAFINITYLABEL  0.002222\n",
      "12                  GENDERCODE  0.002222\n",
      "13              RESORTSVISITED  0.002222\n",
      "14                 TOTALVISITS  0.001111\n",
      "15               GUESTBEHAVIOR  0.000000\n",
      "16                         AGE -0.001111\n",
      "17           MOSTVISITEDRESORT -0.001111\n",
      "18           SKIERABILITYLABEL -0.003333\n",
      "19         TOTALSEASONSSCANNED -0.005556\n",
      "20         ONLYSINGLERESORTKEY -0.007778\n",
      "INFO:root:hold out data preview going to snowflake            ECID SEASONYEAR  PROBABILITY          DATECREATED  \\\n",
      "14448  15244616    2019/20     0.059380  2022-10-26 19:48:47   \n",
      "12515  75518328    2019/20     0.035921  2022-10-26 19:48:47   \n",
      "2167   84430658    2018/19     0.108729  2022-10-26 19:48:47   \n",
      "\n",
      "           EXP_COMMIT_CI_SHA  \n",
      "14448  BASELINE_LocalRunTest  \n",
      "12515  BASELINE_LocalRunTest  \n",
      "2167   BASELINE_LocalRunTest  \n",
      "INFO:data_system_utilities.snowflake.utils:connection to snowflake established...\n",
      "INFO:data_system_utilities.snowflake.query:executing query\n",
      "INFO:data_system_utilities.snowflake.query:data loaded from snowflake\n",
      "INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off\n",
      "INFO:data_system_utilities.snowflake.query:LTBP_HOLDOUT_TEST_MODEL_RESULTS successfully dropped.\n",
      "INFO:data_system_utilities.snowflake.query:creating table LTBP_HOLDOUT_TEST_MODEL_RESULTS\n",
      "INFO:data_system_utilities.snowflake.query:sqlalchemy snowflake engine created\n",
      "INFO:data_system_utilities.snowflake.query:table created\n",
      "INFO:root:saving test prediction file\n",
      "INFO:root:sending prediction file to azure to projects/LTBP/FY23/experiments/BASELINE/holdout_results/\n",
      "INFO:data_system_utilities.azure.storage:Uploading holdout_BASELINE.csv, to Azure Storage projects/LTBP/FY23/experiments/BASELINE/holdout_results/holdout_BASELINE.csv\n",
      "INFO:data_system_utilities.azure.storage:Azure Upload Complete\n",
      "INFO:data_system_utilities.snowflake.query:creating table LTBP_MODEL_TRACKING_FY23\n",
      "INFO:data_system_utilities.snowflake.query:sqlalchemy snowflake engine created\n",
      "INFO:data_system_utilities.snowflake.query:table created\n",
      "INFO:root:project log preview:\n",
      "                                  ACTION_DESCRIPTION TRANSACTION_TYPE  \\\n",
      "0  Standard baseline xgb_hyperopt approach status...   model_training   \n",
      "\n",
      "       COMMITID ENVIRONMENT  BRANCH                         TIMESTAMP  \\\n",
      "0  LocalRunTest         dev  random  2022-10-26 20:48:54.289052-06:00   \n",
      "\n",
      "                                           ARTIFACTS  \\\n",
      "0  \"{\\\"azure_parent_folder\\\": \\\"projects/LTBP/FY2...   \n",
      "\n",
      "                                             METRICS  \n",
      "0  \"{\\\"training_metrics\\\": {\\\"auc\\\": 0.9192113816...  \n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "features, udf_inputs, etl, models = get_yaml_dicts(['features.yaml',\n",
    "                                                    'udf_inputs.yaml',\n",
    "                                                    'etl.yaml', \n",
    "                                                    'models.yaml'])\n",
    "df = create_stage_and_query_stage_sf(\n",
    "    sf=sf,\n",
    "    etl=etl,\n",
    "    udf_inputs=udf_inputs,\n",
    "    train_or_inference=train_or_inference,\n",
    "    experiment_name=experiment_name,\n",
    "    experiment=experiment,\n",
    "    indentification=models['idenfication']\n",
    "    )\n",
    "\n",
    "cat_vars =[{f.upper() : values['transformation'][experiment_name]} for f, values in features.items() \n",
    "            if values['var_type'][experiment_name] == 'cat'\n",
    "            and values['input_definition'] != 'LABEL']\n",
    "cont_vars =[{f.upper(): values['transformation'][experiment_name]} for f, values in features.items() \n",
    "            if values['var_type'][experiment_name] == 'cont'\n",
    "            and values['input_definition'] != 'LABEL']\n",
    "\n",
    "feature_dict = create_sklearn_preprocess_baseline_dict(cat_vars=cat_vars, \n",
    "                                                       cont_vars=cont_vars)\n",
    "logging.info(feature_dict)\n",
    "cat_vars = return_list_of_vars(cat_vars)\n",
    "cont_vars = return_list_of_vars(cont_vars)\n",
    "logging.info(f\"categorical variables: \\n {cat_vars}\")\n",
    "logging.info(f\"continous variables: \\n {cont_vars}\")\n",
    "\n",
    "pipe = preprocessing.generate_sklearn_preprocessing_pipeline(\n",
    "    feature_dict, impute=True, impute_strategy='mean'\n",
    ")\n",
    "\n",
    "adls_path = os.path.join((os.path.join(etl['data_lake_path'], 'experiments', experiment_name)\n",
    "    if experiment \n",
    "    else os.path.join(etl_dict['data_lake_path'], \n",
    "    os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS')))\n",
    "    , models['preprocessors_adls_path'])\n",
    "\n",
    "y_var=[k.upper() for k, v in features.items() if v['input_definition'] == 'LABEL']\n",
    "\n",
    "result = prepare_training_set(df,\n",
    "                              y_var=[k.upper() for k, v in features.items() if v['input_definition'] == 'LABEL'],\n",
    "                              y_scaler_type=models[experiment_name]['y_scaler_type'],\n",
    "                              adls_path=adls_path,\n",
    "                              sklearn_pipe=pipe,\n",
    "                              test_set=True,\n",
    "                              etl_dict=etl,\n",
    "                              models_dict=models,\n",
    "                              connection_str=os.environ[models[\"connection_str\"]],\n",
    "                              experiment_name=experiment_name,\n",
    "                              as_type=int,\n",
    "                              identifiers=['ECID', 'SEASONYEAR']\n",
    "                              )\n",
    "if test_set:\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test, sklearn_pipe, scaler, id_list = result\n",
    "else:\n",
    "    X_train, X_valid, y_train, y_valid, sklearn_pipe, scaler, id_list = result\n",
    "\n",
    "model_trainer = getattr(ds_models, models[experiment_name]['model_trainer'])\n",
    "\n",
    "cat_vars =[{f.upper() : values['transformation'][experiment_name]} for f, values in features.items() \n",
    "            if values['var_type'][experiment_name] == 'cat'\n",
    "            and values['input_definition'] != 'LABEL']\n",
    "cont_vars =[{f.upper(): values['transformation'][experiment_name]} for f, values in features.items() \n",
    "            if values['var_type'][experiment_name] == 'cont'\n",
    "            and values['input_definition'] != 'LABEL']\n",
    "\n",
    "feature_dict = create_sklearn_preprocess_baseline_dict(cat_vars=cat_vars, \n",
    "                                                       cont_vars=cont_vars)\n",
    "logging.info(feature_dict)\n",
    "cat_vars = return_list_of_vars(cat_vars)\n",
    "cont_vars = return_list_of_vars(cont_vars)\n",
    "logging.info(f\"categorical variables: \\n {cat_vars}\")\n",
    "logging.info(f\"continous variables: \\n {cont_vars}\")\n",
    "\n",
    "pipe = preprocessing.generate_sklearn_preprocessing_pipeline(\n",
    "    feature_dict, impute=True, impute_strategy='mean'\n",
    ")\n",
    "\n",
    "adls_path = os.path.join((os.path.join(etl['data_lake_path'], 'experiments', experiment_name)\n",
    "    if experiment\n",
    "    else os.path.join(etl_dict['data_lake_path'],\n",
    "    os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS')))\n",
    "    , models['preprocessors_adls_path'])\n",
    "\n",
    "model = model_trainer(X_train, X_valid, y_train, y_valid,\n",
    "    evals=evals, sub=hyper_sub_size, train=train_size)\n",
    "\n",
    "y_var=[k.upper() for k, v in features.items() if v['input_definition'] == 'LABEL']\n",
    "\n",
    "\"\"\"\n",
    "Custom needs for each project type this works for a binary classification\n",
    "this is not my best work, but trying to put something together \n",
    "this is dry I am sure i could make this just a few lines \n",
    "\"\"\"\n",
    "result_dict = {}\n",
    "logging.info('Training Set Evaluation')\n",
    "\n",
    "eval_list_train = evaluate(model, X_train, y_train, y_var, feature_importance=True)\n",
    "metric1, metric2, metric3, columns, fi_permutation = eval_list_train\n",
    "result_dict['training_metrics']={k: v for k, v in zip(columns, [metric1]+[metric2]+[metric3])}\n",
    "result_dict['fi_train']={k:v for k, v in fi_permutation[:10].values}\n",
    "logging.info('Validation Set Evaluation')\n",
    "eval_list_valid = evaluate(model, X_valid, y_valid, y_var, feature_importance=True)\n",
    "metric1, metric2, metric3, columns, fi_permutation = eval_list_train\n",
    "result_dict['valid_metrics']={k: v for k, v in zip(columns, [metric1]+[metric2]+[metric3])}\n",
    "result_dict['fi_valid']={k:v for k, v in fi_permutation[:10].values}\n",
    "if X_test is not None:\n",
    "    logging.info('Test Set Evaluation')\n",
    "    eval_list_test = evaluate(model, X_test, y_test, y_var, feature_importance=True)\n",
    "    metric1, metric2, metric3, columns, fi_permutation = eval_list_train\n",
    "    result_dict['test_metrics']={k: v for k, v in zip(columns, [metric1]+[metric2]+[metric3])}\n",
    "    result_dict['fi_test']={k:v for k, v in fi_permutation[:10].values}\n",
    "    \n",
    "sf = snowflake_query(sfSchema='LTBP')\n",
    "send_holdout_results_to_sf(sf, id_list, y_pred_proba, experiment, experiment_name, etl, models)\n",
    "\n",
    "adls_path = os.path.join((os.path.join(etl['data_lake_path'], 'experiments', experiment_name)\n",
    "    if experiment \n",
    "    else os.path.join(etl_dict['data_lake_path'], \n",
    "    os.environ.get('CI_COMMIT_SHA', 'LocalRunNBS'))))\n",
    "\n",
    "project_log_df = project_log.project_log(\n",
    "    snowflake_connection=sf,\n",
    "    table_name=models['tracking_table'],\n",
    "    action_description=models[experiment_name][\"description\"],\n",
    "    transaction_type=\"model_training\",\n",
    "    artifacts=json.dumps({\"azure_parent_folder\": adls_path}),\n",
    "    metrics=json.dumps(result_dict),\n",
    "    append_or_replace=\"append\",\n",
    ")\n",
    "logging.info(f'project log preview:\\n{project_log_df.head(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_system_utilities.snowflake.utils:connection to snowflake established...\n",
      "INFO:data_system_utilities.snowflake.query:executing query\n",
      "INFO:data_system_utilities.snowflake.query:data loaded from snowflake\n",
      "INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off\n",
      "INFO:data_system_utilities.snowflake.query:LTBP_MODEL_TRACKING_FY23 successfully dropped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LTBP_MODEL_TRACKING_FY23 successfully dropped.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           status\n",
       "0  LTBP_MODEL_TRACKING_FY23 successfully dropped."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.run_sql_str(\"DROP TABLE LTBP_MODEL_TRACKING_FY23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from data_system_utilities.azure.storage import FileHandling\n",
    "from data_system_utilities.file_parsers import yaml\n",
    "from data_system_utilities.snowflake.utils import make_stage_query_generator\n",
    "\n",
    "from machine_learning_utilities import preprocessing\n",
    "\n",
    "from LTBP.data.utils import snowflake_query, get_yaml_dicts, generate_data_lake_query\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from rfpimp import *\n",
    "\n",
    "import sklearn.preprocessing as y_transform\n",
    "import os\n",
    "import logging\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning_utilities.project_log import project_log\n",
    "from data_system_utilities.azure.storage import FileHandling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_system_utilities.snowflake.utils:connection to snowflake established...\n",
      "INFO:data_system_utilities.snowflake.query:executing query\n",
      "INFO:data_system_utilities.snowflake.query:data loaded from snowflake\n",
      "INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off\n",
      "INFO:data_system_utilities.snowflake.query:LTBP_MODEL_TRACKING_FY23 successfully dropped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LTBP_MODEL_TRACKING_FY23 successfully dropped.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           status\n",
       "0  LTBP_MODEL_TRACKING_FY23 successfully dropped."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.run_sql_str(\"DROP TABLE LTBP_MODEL_TRACKING_FY23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:For Test Set Unseen Data ['BOUGHTPASS'] AUC: 0.899 Accuracy: 0.828 Balanced Accuracy: 0.829\n",
      "INFO:root:Size of Test Data set: 900\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict_proba(X_test)\n",
    "y_pred = model.predict(X_test)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "bacc = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "logging.info(f'For Test Set Unseen Data {y_var} AUC: {auc:.3f} Accuracy: {acc:.3f} Balanced Accuracy: {bacc:.3f}')\n",
    "logging.info(f'Size of Test Data set: {len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_system_utilities.snowflake.query:creating table LTBP_MODEL_TRACKING_FY23\n",
      "INFO:data_system_utilities.snowflake.query:sqlalchemy snowflake engine created\n",
      "INFO:data_system_utilities.snowflake.query:table created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION_DESCRIPTION</th>\n",
       "      <th>TRANSACTION_TYPE</th>\n",
       "      <th>COMMITID</th>\n",
       "      <th>ENVIRONMENT</th>\n",
       "      <th>BRANCH</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>ARTIFACTS</th>\n",
       "      <th>METRICS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard baseline xgb_hyperopt approach status...</td>\n",
       "      <td>model_training</td>\n",
       "      <td>LocalRunTest</td>\n",
       "      <td>dev</td>\n",
       "      <td>random</td>\n",
       "      <td>2022-10-26 20:27:03.842182-06:00</td>\n",
       "      <td>{\"azure_parent_folder\": \"projects/LTBP/FY23/ex...</td>\n",
       "      <td>{\"training_metrics\": {\"auc\": 0.902594497729876...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ACTION_DESCRIPTION TRANSACTION_TYPE  \\\n",
       "0  Standard baseline xgb_hyperopt approach status...   model_training   \n",
       "\n",
       "       COMMITID ENVIRONMENT  BRANCH                         TIMESTAMP  \\\n",
       "0  LocalRunTest         dev  random  2022-10-26 20:27:03.842182-06:00   \n",
       "\n",
       "                                           ARTIFACTS  \\\n",
       "0  {\"azure_parent_folder\": \"projects/LTBP/FY23/ex...   \n",
       "\n",
       "                                             METRICS  \n",
       "0  {\"training_metrics\": {\"auc\": 0.902594497729876...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
