<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Snowflake Feature Store Query or Custom SQL File">

<title>LTBP - Data Creation Script</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="LTBP - Data Creation Script">
<meta property="og:description" content="Snowflake Feature Store Query or Custom SQL File">
<meta property="og:site-name" content="LTBP">
<meta name="twitter:title" content="LTBP - Data Creation Script">
<meta name="twitter:description" content="Snowflake Feature Store Query or Custom SQL File">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">LTBP</span>
    </a>
  </div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Data Creation Script</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Project Overview</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Tutorials</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_preparation_example.html" class="sidebar-item-text sidebar-link">Data Creation Process</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modeling_example.html" class="sidebar-item-text sidebar-link">Iterate Upon a Model</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./calling_library_cli.html" class="sidebar-item-text sidebar-link">Use Your CLI Commands</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Library Scripts</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_creation_script.html" class="sidebar-item-text sidebar-link active">Data Creation Script</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modeling_script.html" class="sidebar-item-text sidebar-link">Modeling Script</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference_script.html" class="sidebar-item-text sidebar-link">Inference Script</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Library Functions</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_utils.html" class="sidebar-item-text sidebar-link">Data Utils</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./model_utilities.html" class="sidebar-item-text sidebar-link">Model Utils</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./models.html" class="sidebar-item-text sidebar-link">Models</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./model_utilities_custom.html" class="sidebar-item-text sidebar-link">Model Utils</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference_utilities.html" class="sidebar-item-text sidebar-link">Inference Utils</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#snowflake-feature-store" id="toc-snowflake-feature-store" class="nav-link active" data-scroll-target="#snowflake-feature-store">Snowflake Feature Store</a>
  <ul class="collapse">
  <li><a href="#data_creation" id="toc-data_creation" class="nav-link" data-scroll-target="#data_creation">data_creation</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/JeremyDemlow/LTBP/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Data Creation Script</h1>
</div>

<div>
  <div class="description">
    Snowflake Feature Store Query or Custom SQL File
  </div>
</div>


<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="snowflake-feature-store" class="level1">
<h1>Snowflake Feature Store</h1>
<blockquote class="blockquote">
<p>This should be the default approach that we use so that all projects pull from similar data definitions</p>
</blockquote>
<p><a href="https://JeremyDemlow.github.io/LTBP/data_creation_script.html#data_creation"><code>data_creation</code></a></p>
<p>This function was created to the library from the section <strong>console_scripts</strong> settings.ini.</p>
<p>To add a new CLI command please go to ./settings.ini find this section and add the scripts that you make.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode ini code-with-copy"><code class="sourceCode ini"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="dt">console_scripts </span><span class="ot">=</span><span class="st"> data_creation=buypass.scripts.preprocess:data_creation</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;name of command line arg&gt; </span><span class="ot">=</span><span class="st"> &lt;library name&gt;.&lt;path to function&gt;.&lt;file name&gt;:&lt;function name&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>What is happpening is this script</strong></p>
<p>What is happpening is this script</p>
<p>Overview:</p>
<ol type="1">
<li><p>Generates a snowflake feature story query is generated from the yaml files features and udf_inputs that are needed to query the feature set of interest.</p>
<ul>
<li><code>get_yaml_dicts</code> –&gt; <code>pull_features_from_snowflake</code> =&gt; generates a string query to be queried</li>
</ul></li>
<li><p>Then the generated query is sent <a href="https://JeremyDemlow.github.io/LTBP/data_utils.html#query_feature_sets_to_adls_parquet_sf_fs"><code>query_feature_sets_to_adls_parquet_sf_fs</code></a> to then send then send to adls for the library to query in the modeling section.</p>
<blockquote class="blockquote">
<p>If you have a use case that needs to take advantage of parquet partitioning then the function allows for that, but standard use cases haven’t needed them so that would just be a nice enhancement</p>
</blockquote></li>
</ol>
<blockquote class="blockquote">
<p>Key Note: the train_or_test is the trigger for test/inference data set.</p>
</blockquote>
<hr>
<p><a href="https://github.com/JeremyDemlow/LTBP/blob/main/LTBP/scripts/data_creation.py#L22" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="data_creation" class="level3">
<h3 class="anchored" data-anchor-id="data_creation">data_creation</h3>
<blockquote class="blockquote">
<pre><code> data_creation (yaml_file_list:list&lt;YAMLfilestoread&gt;,
                train_or_inference:str&lt;Uppercasetrainingorinference&gt;,
                experiment_name:str&lt;Experimentnametoruncasesensetive&gt;, exp
                eriment:&lt;Boolenifit'saexperimentoraruntorunforacommithash&gt;
                )</code></pre>
</blockquote>
<p>Creates a feature set for a experiment data set or a production level run feature set</p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 38%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>yaml_file_list</td>
<td>list <yaml files="" to="" read=""></yaml></td>
<td>noqa:</td>
</tr>
<tr class="even">
<td>train_or_inference</td>
<td>str <upper case="" training="" or="" inference=""></upper></td>
<td>noqa</td>
</tr>
<tr class="odd">
<td>experiment_name</td>
<td>str <experiment name="" to="" run="" case="" sensetive=""></experiment></td>
<td>noqa:</td>
</tr>
<tr class="even">
<td>experiment</td>
<td>&lt;Boolen if it’s a experiment or a run to run for a commit hash&gt;</td>
<td>noqa:</td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>experiment <span class="op">=</span> <span class="va">False</span> <span class="co"># this will trigger if the feature set needs to be created</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>train_or_inference <span class="op">=</span> <span class="st">'TRAINING'</span> <span class="co"># 'INFERENCE'</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>experiment_name<span class="op">=</span><span class="st">'BASELINE'</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>logging.info(<span class="ss">f"This is a </span><span class="sc">{</span><span class="st">'experiment run'</span> <span class="cf">if</span> experiment <span class="cf">else</span> <span class="st">'production run'</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>logging.info(<span class="st">'Loading Yaml Files..'</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>features, udf_inputs, etl <span class="op">=</span> get_yaml_dicts([<span class="st">'features.yaml'</span>, <span class="st">'udf_inputs.yaml'</span>, <span class="st">'etl.yaml'</span>])</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>logging.info(<span class="st">'Generating Feature Set Query'</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>data_lake_path <span class="op">=</span> os.path.join(</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    (os.path.join(etl[<span class="st">'data_lake_path'</span>], <span class="st">'experiments'</span>, experiment_name)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>     <span class="cf">if</span> experiment</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>     <span class="cf">else</span> os.path.join(</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>         etl[<span class="st">'data_lake_path'</span>],</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>         os.environ.get(<span class="st">'CI_COMMIT_SHA'</span>, <span class="st">'LocalRunTest'</span>),</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>         experiment_name</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>     )</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    ), train_or_inference.lower()<span class="op">+</span><span class="st">'_data/'</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>data_lake_path</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co">This is to help a user develop locally for the script if things are changing best method is to pull the above</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="co">cell into this one and begin to develop or you can do this is a .py file, but this is my prefered method</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>experiment <span class="op">=</span> <span class="va">True</span> <span class="co"># this will trigger if the feature set needs to be created</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>train_or_inference <span class="op">=</span> <span class="st">'TRAINING'</span> <span class="co"># 'INFERENCE'</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>experiment_name<span class="op">=</span><span class="st">'BASELINE'</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>logging.info(<span class="ss">f"This is a </span><span class="sc">{</span><span class="st">'experiment run'</span> <span class="cf">if</span> experiment <span class="cf">else</span> <span class="st">'production run'</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>logging.info(<span class="st">'Loading Yaml Files..'</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>features, udf_inputs, etl <span class="op">=</span> get_yaml_dicts([<span class="st">'features.yaml'</span>, <span class="st">'udf_inputs.yaml'</span>, <span class="st">'etl.yaml'</span>])</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>logging.info(<span class="st">'Generating Feature Set Query'</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> pull_features_from_snowflake(feature_dict<span class="op">=</span>features,</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>                                     udf_inputs<span class="op">=</span>udf_inputs[train_or_inference.upper()],</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>                                     filepath_to_grain_list_query<span class="op">=</span><span class="st">'./LTBP/files/sql_files/'</span>,</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>                                     experiment_name<span class="op">=</span>experiment_name)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>data_lake_path <span class="op">=</span> os.path.join((os.path.join(etl[<span class="st">'data_lake_path'</span>], <span class="st">'experiments'</span>, experiment_name)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>                  <span class="cf">if</span> experiment </span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>                  <span class="cf">else</span> os.path.join(etl[<span class="st">'data_lake_path'</span>], </span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>                                    os.environ.get(<span class="st">'CI_COMMIT_SHA'</span>, <span class="st">'LocalRunTest'</span>)))</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>                 , train_or_inference.lower()<span class="op">+</span><span class="st">'_data/'</span>)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>logging.info(<span class="ss">f'Checking </span><span class="sc">{</span>data_lake_path<span class="sc">}</span><span class="ss"> to either skip creation for experiment or create a production dataset'</span>)</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>fh <span class="op">=</span> FileHandling(os.environ[<span class="st">'DATALAKE_CONN_STR_SECRET'</span>])</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>ald_files <span class="op">=</span> fh.ls_blob(path<span class="op">=</span>data_lake_path, container_name<span class="op">=</span>etl[<span class="st">'azure_container'</span>])</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>sf <span class="op">=</span> snowflake_query()</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> ald_files <span class="op">==</span> []:</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>    query_feature_sets_to_adls_parquet_sf_fs(</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>        sf_connection<span class="op">=</span>sf,</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>        sf_query<span class="op">=</span>query,</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>        query_file_path<span class="op">=</span>os.path.join(files.__path__[<span class="dv">0</span>], etl[<span class="st">'query_file_path'</span>]),</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>        azure_account<span class="op">=</span>etl[<span class="st">"azure_account"</span>],</span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>        azure_container<span class="op">=</span>etl[<span class="st">"azure_container"</span>],</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>        data_lake_path<span class="op">=</span>data_lake_path, <span class="co"># </span><span class="al">TODO</span><span class="co">: Think about experiments versus </span></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>        partition_by<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>        data_lake_sas_token<span class="op">=</span>os.environ[<span class="st">"DATALAKE_SAS_TOKEN_SECRET"</span>],</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>    logging.warning(<span class="ss">f'</span><span class="sc">{</span>data_lake_path<span class="sc">}</span><span class="ss"> already exists this should be do experimentation runs'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:root:This is a production run
INFO:root:Loading Yaml Files..
INFO:root:Generating Feature Set Query</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>'projects/LTBP/FY23/LocalRunTest/BASELINE/training_data/'</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> LTBP.data.utils <span class="im">import</span> snowflake_query, get_yaml_dicts, generate_data_lake_query</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> LTBP <span class="im">import</span> files</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> data_system_utilities.file_parsers <span class="im">import</span> yaml</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> data_system_utilities.snowflake.utils <span class="im">import</span> make_stage_query_generator</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>stage_url <span class="op">=</span> <span class="ss">f"""azure://</span><span class="sc">{</span>etl[<span class="st">'azure_account'</span>]<span class="sc">}</span><span class="ss">.blob.core.windows.net/</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="sc">{</span>etl[<span class="st">'azure_container'</span>]<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>etl[<span class="st">'data_lake_path'</span>]<span class="sc">}{</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>(os.path.join(<span class="st">'experiments'</span>, experiment_name)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> experiment </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span> os.path.join(<span class="st">'LocalRunTest'</span>))<span class="sc">}</span><span class="ss">"""</span>.replace(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>, <span class="st">''</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>stage_query <span class="op">=</span> make_stage_query_generator(</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    stage_name<span class="op">=</span>etl[<span class="st">"stage_name"</span>] <span class="op">+</span> etl[<span class="st">'FY_folder'</span>] <span class="op">+</span> os.environ.get(<span class="st">'CI_COMMIT_SHA'</span>, <span class="st">'LocalRunTest'</span>),</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    url<span class="op">=</span>stage_url,</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    sas_token<span class="op">=</span>os.environ[<span class="st">"DATALAKE_SAS_TOKEN_SECRET"</span>],</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    file_type<span class="op">=</span><span class="st">"parquet"</span>,</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> sf.run_sql_str(stage_query)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Figure out a identification feature like season year </span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Udf grain is ECID, which is easy to get, but season year isn't obivous some thought is needed</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>indentification <span class="op">=</span> [col.split(<span class="st">'.'</span>)[<span class="op">-</span><span class="dv">1</span>] <span class="cf">for</span> col <span class="kw">in</span> udf_inputs[train_or_inference][<span class="st">'UDF_GRAIN'</span>]]</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>columns <span class="op">=</span> [col.upper() <span class="cf">for</span> col <span class="kw">in</span> features.keys()]</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> generate_data_lake_query(stage_name<span class="op">=</span>(etl[<span class="st">"stage_name"</span>] </span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>                                             <span class="op">+</span> etl[<span class="st">'FY_folder'</span>] </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>                                             <span class="op">+</span> os.environ.get(<span class="st">'CI_COMMIT_SHA'</span>, <span class="st">'LocalRunTest'</span>)),</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>     stage_path<span class="op">=</span>train_or_inference.lower()<span class="op">+</span><span class="st">'_data/'</span>,</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>     columns<span class="op">=</span>indentification <span class="op">+</span> columns,</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>     extra_statement<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>logging.info(<span class="ss">f'adls snowflake stage query </span><span class="sc">{</span>query<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> sf.run_sql_str(query)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>logging.info(<span class="ss">f'Preview dataframe queried </span><span class="sc">{</span>df<span class="sc">.</span>head()<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co">This is to help a user develop locally for the script if things are changing best method is to pull the above</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">cell into this one and begin to develop or you can do this is a .py file, but this is my prefered method</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>experiment <span class="op">=</span> <span class="st">'True'</span> <span class="co"># this will trigger if the feature set needs to be created</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>train_or_inference <span class="op">=</span><span class="st">'INFERENCE'</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>experiment_name<span class="op">=</span><span class="st">'BASELINE'</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>experiment <span class="op">=</span> <span class="va">True</span> <span class="cf">if</span> experiment.lower() <span class="op">==</span> <span class="st">'true'</span> <span class="cf">else</span> <span class="va">False</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>logging.info(<span class="ss">f"This is a </span><span class="sc">{</span><span class="st">'experiment run'</span> <span class="cf">if</span> experiment <span class="cf">else</span> <span class="st">'production run'</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>logging.info(<span class="st">'Loading Yaml Files..'</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>features, udf_inputs, etl <span class="op">=</span> get_yaml_dicts([<span class="st">'features.yaml'</span>, <span class="st">'udf_inputs.yaml'</span>, <span class="st">'etl.yaml'</span>])</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>logging.info(<span class="st">'Generating Feature Set Query'</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> pull_features_from_snowflake(feature_dict<span class="op">=</span>features,</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>                                     udf_inputs<span class="op">=</span>udf_inputs[train_or_inference.upper()],</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>                                     filepath_to_grain_list_query<span class="op">=</span><span class="st">'./LTBP/files/sql_files/'</span>,</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>                                     experiment_name<span class="op">=</span>experiment_name)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>data_lake_path <span class="op">=</span> os.path.join((os.path.join(etl[<span class="st">'data_lake_path'</span>], <span class="st">'experiments'</span>, experiment_name)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>                  <span class="cf">if</span> experiment </span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>                  <span class="cf">else</span> os.path.join(etl[<span class="st">'data_lake_path'</span>], </span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>                                    os.environ.get(<span class="st">'CI_COMMIT_SHA'</span>, <span class="st">'LocalRunTest'</span>)))</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>                 , train_or_inference.lower()<span class="op">+</span><span class="st">'_data/'</span>)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>logging.info(<span class="ss">f'Checking </span><span class="sc">{</span>data_lake_path<span class="sc">}</span><span class="ss"> to either skip creation for experiment or create a production dataset'</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>fh <span class="op">=</span> FileHandling(os.environ[<span class="st">'DATALAKE_CONN_STR_SECRET'</span>])</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>ald_files <span class="op">=</span> fh.ls_blob(path<span class="op">=</span>data_lake_path, container_name<span class="op">=</span>etl[<span class="st">'azure_container'</span>])</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>sf <span class="op">=</span> snowflake_query()</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> ald_files <span class="op">==</span> []:</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    query_feature_sets_to_adls_parquet_sf_fs(</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>        sf_connection<span class="op">=</span>sf,</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>        sf_query<span class="op">=</span>query,</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>        query_file_path<span class="op">=</span>os.path.join(files.__path__[<span class="dv">0</span>], etl[<span class="st">'query_file_path'</span>]),</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>        azure_account<span class="op">=</span>etl[<span class="st">"azure_account"</span>],</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>        azure_container<span class="op">=</span>etl[<span class="st">"azure_container"</span>],</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>        data_lake_path<span class="op">=</span>data_lake_path, <span class="co"># </span><span class="al">TODO</span><span class="co">: Think about experiments versus </span></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>        partition_by<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>        data_lake_sas_token<span class="op">=</span>os.environ[<span class="st">"DATALAKE_SAS_TOKEN_SECRET"</span>],</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>    logging.warning(<span class="ss">f'</span><span class="sc">{</span>data_lake_path<span class="sc">}</span><span class="ss"> already exists this should be do experimentation runs'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:root:This is a experiment run
INFO:root:Loading Yaml Files..
INFO:root:Generating Feature Set Query
INFO:root:static features in data set: 
 ['DESTINATIONGEOAFINITYLABEL', 'GenderCode']
INFO:root:temporal features in data set: 
 ['Age', 'AvgVisitPerSeason', 'BoughtPass', 'EverCorePass', 'EverPass', 'GuestBehavior', 'IsEpicMixActivated', 'MarketingZone', 'MostCommonTicketComp', 'MostSubSeasonVisited', 'MostVisitedRegion', 'MostVisitedResort', 'OnlySingleResortKey', 'PartnerResortScannerFlag', 'ResortsVisited', 'SkierabilityLabel', 'SubSeasonsPerYear', 'TotalSeasonsScanned', 'TotalVisits', 'VisitMostInPeak']
INFO:root:Appending static feature DESTINATIONGEOAFINITYLABEL to query
INFO:root:Appending static feature GenderCode to query
INFO:root:Finished appending static features
INFO:root:reading inference_base.sql for base query...
INFO:root:final query output: 
 select
base.*
, joined.DESTINATIONGEOAFINITYLABEL
, joined.GenderCode
, MACHINELEARNINGFEATURES.PROD.Age_ECID_Temporal(base.ECID, 20190101, 20221005) as Age, MACHINELEARNINGFEATURES.PROD.AvgVisitPerSeason_ECID_Temporal(base.ECID, 20190101, 20221005) as AvgVisitPerSeason, MACHINELEARNINGFEATURES.PROD.BoughtPass_ECID_Temporal(base.ECID, '2021/22') as BoughtPass, MACHINELEARNINGFEATURES.PROD.EverCorePass_ECID_Temporal(base.ECID, 20051001, 20221005) as EverCorePass, MACHINELEARNINGFEATURES.PROD.EverPass_ECID_Temporal(base.ECID, 20051001, 20221005) as EverPass, MACHINELEARNINGFEATURES.PROD.GuestBehavior_ECID_Temporal(base.ECID, '2021/22') as GuestBehavior, MACHINELEARNINGFEATURES.PROD.IsEpicMixActivated_ECID_Temporal(base.ECID, '2021/22') as IsEpicMixActivated, MACHINELEARNINGFEATURES.PROD.MarketingZone_ECID_Temporal(base.ECID, '2021/22') as MarketingZone, MACHINELEARNINGFEATURES.PROD.MostCommonTicketComp_ECID_Temporal(base.ECID, 20190101, 20221005) as MostCommonTicketComp, MACHINELEARNINGFEATURES.PROD.MostSubSeasonVisited_ECID_Temporal(base.ECID, 20190101, 20221005) as MostSubSeasonVisited, MACHINELEARNINGFEATURES.PROD.MostVisitedRegion_ECID_Temporal(base.ECID, 20190101, 20221005) as MostVisitedRegion, MACHINELEARNINGFEATURES.PROD.MostVisitedResort_ECID_Temporal(base.ECID, 20190101, 20221005) as MostVisitedResort, MACHINELEARNINGFEATURES.PROD.OnlySingleResortKey_ECID_Temporal(base.ECID, 20190101, 20221005) as OnlySingleResortKey, MACHINELEARNINGFEATURES.PROD.PartnerResortScannerFlag_ECID_Temporal(base.ECID, 20190101, 20221005) as PartnerResortScannerFlag, MACHINELEARNINGFEATURES.PROD.ResortsVisited_ECID_Temporal(base.ECID, 20190101, 20221005) as ResortsVisited, MACHINELEARNINGFEATURES.PROD.SkierabilityLabel_ECID_Temporal(base.ECID, '2021/22') as SkierabilityLabel, MACHINELEARNINGFEATURES.PROD.SubSeasonsPerYear_ECID_Temporal(base.ECID, 20190101, 20221005) as SubSeasonsPerYear, MACHINELEARNINGFEATURES.PROD.TotalSeasonsScanned_ECID_Temporal(base.ECID, 20190101, 20221005) as TotalSeasonsScanned, MACHINELEARNINGFEATURES.PROD.TotalVisits_ECID_Temporal(base.ECID, 20190101, 20221005) as TotalVisits, MACHINELEARNINGFEATURES.PROD.VisitMostInPeak_ECID_Temporal(base.ECID, 20190101, 20221005) as VisitMostInPeak

, '2021/22' as SEASONYEAR
from
(-- base EDEE team guest behavior
  with edee_base as (
      SELECT 
            distinct ECID
      from BIDE_EDWDB_CUSTOMERMART_PROD.DBO.CustomerPASSPURCHASEBEHAVIOR cla
      where 
              cla.GuestPassPurchaseBehaviorDetailLabel &lt;&gt; 'Unknown'
  ),

  -- pass prospects not in guest behavior
  prospects as (
      Select
            distinct ECID
      from Vail_Reporting.Prod.GuestBehaviorBase
      where 
              GuestBehavior = 'Prospect'
          and salesseason = '2021/22'
  ),

  -- paid prospects not in guest behavior
  other_scans as (
      select
            distinct a.ECID
      from
      (
          select 
                distinct ECID
              , SeasonYear
          from "BIDE_EDWDB_ARA_PROD"."DBO"."SCANDAY"
              where Season = 'Winter'
      ) a
      left join Vail_Reporting.Prod.GuestBehaviorBase b 
          on a.ECID = b.ECID and a.SeasonYear = b.SalesSeason
      where 
              b.GuestBehavior is null
          and a.seasonyear = '2021/22'
  )

  select
        distinct ECID
      , 'Inference Set' as SeasonYear
  from
  (
      select
            coalesce(base.ecid, pro.ecid, os.ecid) as ecid
      from edee_base base
      full outer join prospects pro
          on pro.ecid = base.ecid
      full outer join other_scans os
          on os.ecid = base.ecid
  ) a)base
inner join machinelearningfeatures.prod.featurestore_ecid joined on joined.ecid = base.ecid
INFO:root:Checking projects/LTBP/FY23/experiments/BASELINE/inference_data/ to either skip creation for experiment or create a production dataset
INFO:data_system_utilities.azure.storage:number of files in container path recursively 0
INFO:data_system_utilities.snowflake.copyinto:
COPY INTO 'azure://vaildtscadls.blob.core.windows.net/vailadls/projects/LTBP/FY23/experiments/BASELINE/inference_data/'
FROM (select
base.*
, joined.DESTINATIONGEOAFINITYLABEL
, joined.GenderCode
, MACHINELEARNINGFEATURES.PROD.Age_ECID_Temporal(base.ECID, 20190101, 20221005) as Age, MACHINELEARNINGFEATURES.PROD.AvgVisitPerSeason_ECID_Temporal(base.ECID, 20190101, 20221005) as AvgVisitPerSeason, MACHINELEARNINGFEATURES.PROD.BoughtPass_ECID_Temporal(base.ECID, '2021/22') as BoughtPass, MACHINELEARNINGFEATURES.PROD.EverCorePass_ECID_Temporal(base.ECID, 20051001, 20221005) as EverCorePass, MACHINELEARNINGFEATURES.PROD.EverPass_ECID_Temporal(base.ECID, 20051001, 20221005) as EverPass, MACHINELEARNINGFEATURES.PROD.GuestBehavior_ECID_Temporal(base.ECID, '2021/22') as GuestBehavior, MACHINELEARNINGFEATURES.PROD.IsEpicMixActivated_ECID_Temporal(base.ECID, '2021/22') as IsEpicMixActivated, MACHINELEARNINGFEATURES.PROD.MarketingZone_ECID_Temporal(base.ECID, '2021/22') as MarketingZone, MACHINELEARNINGFEATURES.PROD.MostCommonTicketComp_ECID_Temporal(base.ECID, 20190101, 20221005) as MostCommonTicketComp, MACHINELEARNINGFEATURES.PROD.MostSubSeasonVisited_ECID_Temporal(base.ECID, 20190101, 20221005) as MostSubSeasonVisited, MACHINELEARNINGFEATURES.PROD.MostVisitedRegion_ECID_Temporal(base.ECID, 20190101, 20221005) as MostVisitedRegion, MACHINELEARNINGFEATURES.PROD.MostVisitedResort_ECID_Temporal(base.ECID, 20190101, 20221005) as MostVisitedResort, MACHINELEARNINGFEATURES.PROD.OnlySingleResortKey_ECID_Temporal(base.ECID, 20190101, 20221005) as OnlySingleResortKey, MACHINELEARNINGFEATURES.PROD.PartnerResortScannerFlag_ECID_Temporal(base.ECID, 20190101, 20221005) as PartnerResortScannerFlag, MACHINELEARNINGFEATURES.PROD.ResortsVisited_ECID_Temporal(base.ECID, 20190101, 20221005) as ResortsVisited, MACHINELEARNINGFEATURES.PROD.SkierabilityLabel_ECID_Temporal(base.ECID, '2021/22') as SkierabilityLabel, MACHINELEARNINGFEATURES.PROD.SubSeasonsPerYear_ECID_Temporal(base.ECID, 20190101, 20221005) as SubSeasonsPerYear, MACHINELEARNINGFEATURES.PROD.TotalSeasonsScanned_ECID_Temporal(base.ECID, 20190101, 20221005) as TotalSeasonsScanned, MACHINELEARNINGFEATURES.PROD.TotalVisits_ECID_Temporal(base.ECID, 20190101, 20221005) as TotalVisits, MACHINELEARNINGFEATURES.PROD.VisitMostInPeak_ECID_Temporal(base.ECID, 20190101, 20221005) as VisitMostInPeak

, '2021/22' as SEASONYEAR
from
(-- base EDEE team guest behavior
  with edee_base as (
      SELECT 
            distinct ECID
      from BIDE_EDWDB_CUSTOMERMART_PROD.DBO.CustomerPASSPURCHASEBEHAVIOR cla
      where 
              cla.GuestPassPurchaseBehaviorDetailLabel &lt;&gt; 'Unknown'
  ),

  -- pass prospects not in guest behavior
  prospects as (
      Select
            distinct ECID
      from Vail_Reporting.Prod.GuestBehaviorBase
      where 
              GuestBehavior = 'Prospect'
          and salesseason = '2021/22'
  ),

  -- paid prospects not in guest behavior
  other_scans as (
      select
            distinct a.ECID
      from
      (
          select 
                distinct ECID
              , SeasonYear
          from "BIDE_EDWDB_ARA_PROD"."DBO"."SCANDAY"
              where Season = 'Winter'
      ) a
      left join Vail_Reporting.Prod.GuestBehaviorBase b 
          on a.ECID = b.ECID and a.SeasonYear = b.SalesSeason
      where 
              b.GuestBehavior is null
          and a.seasonyear = '2021/22'
  )

  select
        distinct ECID
      , 'Inference Set' as SeasonYear
  from
  (
      select
            coalesce(base.ecid, pro.ecid, os.ecid) as ecid
      from edee_base base
      full outer join prospects pro
          on pro.ecid = base.ecid
      full outer join other_scans os
          on os.ecid = base.ecid
  ) a)base
inner join machinelearningfeatures.prod.featurestore_ecid joined on joined.ecid = base.ecid)

max_file_size = 3200000
overwrite = True
file_format = (type = parquet          )
credentials= (azure_sas_token = '**MASKED**')
header = True;</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:data_system_utilities.snowflake.utils:connection to snowflake established...
INFO:data_system_utilities.snowflake.query:executing query
INFO:data_system_utilities.snowflake.query:data loaded from snowflake
INFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off
INFO:root:data has been delivered from sf to adls</code></pre>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>